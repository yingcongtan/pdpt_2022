{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.util import calculate_truck_travel_cost, read_pdpt_pickle, read_route_solution_PDPT\n",
    "import pickle\n",
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import permutations\n",
    "\n",
    "DATA_DIR = '/home/tan/Documents/GitHub/pdpt_2022'\n",
    "\n",
    "case_num = 1\n",
    "verbose = 1\n",
    "undelivered_cargos = {}\n",
    "\n",
    "def unique_pair(list1, list2):\n",
    "    unique_combinations = []\n",
    " \n",
    "    # Getting all permutations of list_1\n",
    "    # with length of list_2\n",
    "    permut = itertools.permutations(list1, len(list2))\n",
    "    \n",
    "    # zip() is called to pair each permutation\n",
    "    # and shorter list element into combination\n",
    "    for comb in permut:\n",
    "        zipped = zip(comb, list2)\n",
    "        unique_combinations.append(list(zipped))\n",
    "    \n",
    "    return unique_combinations\n",
    "\n",
    "def sort_(dict, ascending = True):\n",
    "    assert ascending in [True,False]\n",
    "    # idx = dict[:, 1].argsort()\n",
    "\n",
    "    idx = dict[:, 1].astype(np.double).argsort()\n",
    "    if ascending == True:\n",
    "        dict = dict[idx, :]\n",
    "    else:\n",
    "        dict = dict[idx[::-1], :]\n",
    "    dict_sorted = list(dict[:,0])\n",
    "\n",
    "    return dict_sorted\n",
    "\n",
    "def manal_break_for_insepction():\n",
    "    abc = 1 \n",
    "    assert abc==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_inisol(case_num):\n",
    "\n",
    "    filename = DATA_DIR + f'/out/case{case_num}initSol.txt'\n",
    "\n",
    "    truck_yCycle_file, truck_used_file, truck_route_file, \\\n",
    "    cargo_route_file, S_sol_file, A_sol_file, D_sol_file, \\\n",
    "    Sb_sol_file, Ab_sol_file, Db_sol_file = read_route_solution_PDPT(filename, verbose = 0)\n",
    "\n",
    "    undel_cargos = [key for key, value in cargo_route_file.items() if len(value)==0]\n",
    "\n",
    "\n",
    "    return undel_cargos \n",
    "\n",
    "# _=read_inisol(case_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sort_truck_by_distance_from_cargo(cargo_key, cargo_list, truck_list, truck_route_list, edge_distance, verbose = 0):\n",
    "    csize, c_lb_time, c_ub_time, c_origin, c_dest = cargo_list[cargo_key]\n",
    "    total_distance = {}\n",
    "    for t_key, t_value in truck_list.items():\n",
    "        if verbose > 0: print(f'\\tconsider truck [{t_key}]')\n",
    "        route_ = truck_route_list[t_key]\n",
    "        distance = []\n",
    "        if len(route_) >= 2:\n",
    "            # collect a list of distances from a node on truck route  to cargo' origin\n",
    "            distance.append(sum([edge_distance[(route_[i], c_origin)] for i in range(len(route_))]))\n",
    "            # collect a list of distances from cargo' origin from a node on truck route \n",
    "            distance.append(sum([edge_distance[(c_origin, route_[i] )] for i in range(1, len(route_))]))\n",
    "            # collect a list of distances from a node on truck route  to cargo' destination\n",
    "            distance.append(sum([edge_distance[(route_[i], c_dest)] for i in range(1, len(route_))]))\n",
    "            # collect a list of distances from cargo' destination from a node on truck route \n",
    "            distance.append(sum([edge_distance[(c_dest, route_[i] )] for i in range(1, len(route_))]))\n",
    "\n",
    "            total_distance[t_key]= sum(distance)\n",
    "            if verbose > 0: print(f'\\ttotal distance between cargo [{cargo_key}] and truck [{t_key}] is [{total_distance[t_key]}]')\n",
    "        else:\n",
    "            total_distance[t_key]= 100000 # give a arbitrarily large number so t_key will not be considered in best_insertion\n",
    "            if verbose > 0: print(f'\\ttruck[{t_key}] is not used, assign an arbitarily large number 100000 so that it is less favorable')\n",
    "\n",
    "    dist = np.array([ [k, v] for k, v in total_distance.items()]).reshape(-1,2)\n",
    "    dist_sorted = sort_(dist, ascending = True)\n",
    "\n",
    "    return total_distance, dist_sorted\n",
    "\n",
    "def sort_truck_by_workhr_slackness(truck_list, truck_yCycle_file, DT_sol, DT_b_sol, verbose = 0):\n",
    "    workhr_slack = {}\n",
    "    for t_key, t_value in truck_list.items():\n",
    "        t_origin, t_dest, t_max_workhr, t_max_cap = t_value\n",
    "        total_workhr = DT_b_sol[(t_dest, t_key)] - DT_b_sol[(t_origin, t_key)] if t_key in truck_yCycle_file\\\n",
    "                            else DT_sol[(t_dest, t_key)] - DT_sol[(t_origin, t_key)]\n",
    "        workhr_slack[t_key] = t_max_workhr - total_workhr\n",
    "        if verbose> 0:\n",
    "            print(f'truck [{t_key}] departuring its dest [{t_dest}] at {total_workhr}')\n",
    "            print(f'   with max_worktime [{t_max_workhr}], total slack in workhr is [{workhr_slack[t_key]}]')\n",
    "\n",
    "    slack = np.array([ [k, v] for k, v in workhr_slack.items()]).reshape(-1,2)\n",
    "    # slack = slack[slack[:,1].nonzero()]\n",
    "    idx_nonzero = slack[:,1].astype(np.int32).nonzero()[0]\n",
    "    slack = slack[idx_nonzero,:]\n",
    "    slack_sorted = sort_(slack, ascending = False)\n",
    "\n",
    "    return workhr_slack, slack_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_truck_by_slacknesS_distance(pdpt_ins, solution_file, verbose):\n",
    "    sorted_truck_list = {}\n",
    "    truck_yCycle_file, truck_used_file, truck_route_file, \\\n",
    "    cargo_route_file, S_sol_file, A_sol_file, D_sol_file, \\\n",
    "    Sb_sol_file, Ab_sol_file, Db_sol_file = solution_file\n",
    "\n",
    "    undelivered_cargos = [key for key, value in cargo_route_file.items() if len(value)==0]\n",
    "\n",
    "\n",
    "    cargo_list = pdpt_ins['cargo']\n",
    "        # truck['nb_truck'] = ['departure_node', 'arrival_node', 'max_worktime', 'max_capacity']\n",
    "    truck_list = pdpt_ins['truck']\n",
    "    edge_shortest = pdpt_ins['edge_shortest']\n",
    "\n",
    "    distance_sorted = {}\n",
    "    for cargo_key in undelivered_cargos:\n",
    "        print(f'Cargo [{cargo_key}] is not delivered, we consider it for best_insertion')\n",
    "\n",
    "        print(f'   +++ Find trucks with available workhr and sort in workhr_slackness')\n",
    "        truck_slack, slack_sorted = sort_truck_by_workhr_slackness(truck_list, truck_yCycle_file, \n",
    "                                                        D_sol_file, Db_sol_file, verbose = 0)\n",
    "        print(f'\\tsorted truck list trucks {[[t_key, truck_slack[t_key]] for t_key in slack_sorted]}')\n",
    "\n",
    "        print(f'   +++ Find trucks with available workhr and sort in distances from the cargo')\n",
    "        truck_list_ = {t_key: truck_list[t_key] for t_key in slack_sorted}\n",
    "        truck_route_file_ = {t_key: truck_route_file[t_key] for t_key in slack_sorted}\n",
    "        truck_dis, dis_sorted = sort_truck_by_distance_from_cargo(cargo_key, cargo_list, truck_list_, \n",
    "                                                        truck_route_file_, edge_shortest, verbose = 0)\n",
    "        print(f'\\tsorted truck list trucks {[[t_key, truck_dis[t_key]] for t_key in dis_sorted]}')\n",
    "\n",
    "\n",
    "        total_score = np.array([[t_key, len(slack_sorted)*2\\\n",
    "                                - np.where(slack_sorted == np.array(t_key))[0][0]\\\n",
    "                                    - np.where(dis_sorted == np.array(t_key))[0][0]]\n",
    "                            for t_key in slack_sorted])\n",
    "        total_score_sorted = sort_(total_score, False)\n",
    "        print(f'   +++ Rank truck based on slackness and distance:')\n",
    "        print(f'\\t[{total_score_sorted}]')\n",
    "        sorted_truck_list[cargo_key] = total_score_sorted\n",
    "\n",
    "        print('\\n')\n",
    "    return sorted_truck_list, truck_slack, truck_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargo [C80] is not delivered, we consider it for best_insertion\n",
      "   +++ Find trucks with available workhr and sort in workhr_slackness\n",
      "\tsorted truck list trucks [['T1', 61], ['T11', 53], ['T13', 41], ['T8', 20], ['T5', 19], ['T6', 16], ['T2', 16], ['T12', 3], ['T20', 2], ['T17', 1]]\n",
      "   +++ Find trucks with available workhr and sort in distances from the cargo\n",
      "\tsorted truck list trucks [['T1', 2051], ['T5', 2355], ['T11', 2429], ['T20', 2507], ['T13', 3603], ['T6', 4016], ['T2', 4916], ['T17', 5053], ['T8', 5624], ['T12', 6635]]\n",
      "   +++ Rank truck based on slackness and distance:\n",
      "\t[['T1', 'T11', 'T5', 'T13', 'T6', 'T20', 'T8', 'T2', 'T17', 'T12']]\n",
      "\n",
      "\n",
      "Cargo [C228] is not delivered, we consider it for best_insertion\n",
      "   +++ Find trucks with available workhr and sort in workhr_slackness\n",
      "\tsorted truck list trucks [['T1', 61], ['T11', 53], ['T13', 41], ['T8', 20], ['T5', 19], ['T6', 16], ['T2', 16], ['T12', 3], ['T20', 2], ['T17', 1]]\n",
      "   +++ Find trucks with available workhr and sort in distances from the cargo\n",
      "\tsorted truck list trucks [['T11', 1799], ['T1', 2053], ['T20', 2228], ['T5', 2483], ['T13', 3096], ['T6', 3621], ['T2', 4342], ['T8', 4622], ['T12', 4861], ['T17', 4997]]\n",
      "   +++ Rank truck based on slackness and distance:\n",
      "\t[['T11', 'T1', 'T13', 'T5', 'T20', 'T6', 'T8', 'T2', 'T12', 'T17']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = DATA_DIR + f'/out/case{case_num}initSol.txt'\n",
    "pdpt_ins1 = read_pdpt_pickle(case_num, DATA_DIR+'/data', verbose = verbose-1) \n",
    "\n",
    "truck_yCycle_file, truck_used_file, truck_route_file, \\\n",
    "cargo_route_file, S_sol_file, A_sol_file, D_sol_file, \\\n",
    "Sb_sol_file, Ab_sol_file, Db_sol_file = read_route_solution_PDPT(filename, verbose = 0)\n",
    "\n",
    "\n",
    "solution_file = (truck_yCycle_file, truck_used_file, truck_route_file, \\\n",
    "                cargo_route_file, S_sol_file, A_sol_file, D_sol_file, \\\n",
    "                Sb_sol_file, Ab_sol_file, Db_sol_file)\n",
    "\n",
    "sorted_truck_list, truck_slackness, _ = rank_truck_by_slacknesS_distance(pdpt_ins1, solution_file, verbose = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_best_insertion(undelivered_cargo, common_node, t_key1, t_key2, truck_list, edge_shortest, solution_file):\n",
    "    c_key, c_value = undelivered_cargo.items()\n",
    "    # cargo['nb_cargo'] = ['size', 'lb_time', 'ub_time', 'departure_node', 'arrival_node']\n",
    "    c_size, c_lb_time, c_ub_time, c_origin, c_dest = c_value\n",
    "    truck_yCycle_file, truck_used_file, truck_route_file, \\\n",
    "    cargo_route_file, S_sol_file, A_sol_file, D_sol_file, \\\n",
    "    Sb_sol_file, Ab_sol_file, Db_sol_file = solution_file\n",
    "\n",
    "    # for truck1\n",
    "        # for i in common_node ... origin+1\n",
    "    \n",
    "    idx_ = truck_route_file[t_key1].index(common_node)\n",
    "    route_before, route_after = truck_route_file[t_key1][:idx_], truck_route_file[t_key1][idx:_]\n",
    "    for node in truck_route_file[t_key1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_capacity_constraints(node_, S_sol, truck_list, truck_key, cargo_size ):\n",
    "    print(f'\\t   Checking capacity constraints')\n",
    "    print(f'\\t    -- total size of cargos leave {node_} is [{S_[(node_, truck_key)]}]')\n",
    "    print(f'\\t    -- available capacity is {truck_list[truck_key][-1] - S_[(node_, truck_key)]}')\n",
    "    print(f'\\t    -- cargo size capacity is {c_size}')\n",
    "\n",
    "    if truck_list[truck_key][-1] - S_[(node_, truck_key)] > c_size:\n",
    "        print(f'\\t    -- truck capacity constraint satisfied')\n",
    "        return True\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargo [C80] is not delivered, we consider it for best_insertion\n",
      "   truck[T1] route ['N7', 'N2', 'N30']\n",
      "   truck[T13] route ['N10', 'N27', 'N19', 'N30', 'N17']\n",
      "   common nodes are {'N30'}\n",
      "   truck[T1] route ['N7', 'N2', 'N30']\n",
      "   truck[T20] route ['N11', 'N7', 'N14', 'N15']\n",
      "   common nodes are {'N7'}\n",
      "   truck[T1] route ['N7', 'N2', 'N30']\n",
      "   truck[T2] route ['N7', 'N11', 'N5', 'N19', 'N1', 'N16', 'N13']\n",
      "   common nodes are {'N7'}\n",
      "   truck[T1] route ['N7', 'N2', 'N30']\n",
      "   truck[T17] route ['N11', 'N7', 'N14', 'N15', 'N9', 'N3', 'N16']\n",
      "   common nodes are {'N7'}\n",
      "   truck[T1] route ['N7', 'N2', 'N30']\n",
      "   truck[T12] route ['N10', 'N7', 'N5', 'N11', 'N25', 'N12', 'N18', 'N22', 'N20']\n",
      "   common nodes are {'N7'}\n",
      "   truck[T11] route ['N10', 'N19', 'N21', 'N14']\n",
      "   truck[T5] route ['N5', 'N21', 'N9', 'N4']\n",
      "   common nodes are {'N21'}\n",
      "\tfind a common node [N21] that is not a origin or destination of truck\n",
      "['N10', 'N19', 'N21', 'N14'] ['N10', 'N19', 'N21'] ['N21', 'N14']\n",
      "\t   Checking capacity constraints\n",
      "\t    -- total size of cargos leave N19 is [5672]\n",
      "\t    -- available capacity is 6881\n",
      "\t    -- cargo size capacity is 160\n",
      "\t    -- truck capacity constraint satisfied\n",
      "\t    -- leave [N19] at 367\n",
      "\t    -- edge_shortest from N19 to origin of cargo C80 at N5 is 194\n",
      "\t   Checking work time constraints\n",
      "\t    -- leave [N19] at 367\n",
      "\t    -- edge_shortest from N19 to origin of cargo C80 at N5 is 194\n",
      "\t    -- arrive cargo origin [N5] at 561\n",
      "\t    -- leaving cargo origin [N5] at 563\n",
      "\t    -- original arrival time the next node [N21] at 465\n",
      "\t    -- entering the next node [N21] at 835\n",
      "\t    -- departure the dest node of truck T11 [N14] at 1134\n",
      "\t    -- truck T11 max_workhr is [709] \n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/tan/Documents/GitHub/pdpt_2022/WIP_best_insertion.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tan/Documents/GitHub/pdpt_2022/WIP_best_insertion.ipynb#W6sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m    -- departure the dest node of truck \u001b[39m\u001b[39m{\u001b[39;00mt_key1\u001b[39m}\u001b[39;00m\u001b[39m [\u001b[39m\u001b[39m{\u001b[39;00mtruck_list[t_key1][\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m] at \u001b[39m\u001b[39m{\u001b[39;00mD_[(truck_list[t_key1][\u001b[39m1\u001b[39m], t_key1)] \u001b[39m+\u001b[39m cost\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tan/Documents/GitHub/pdpt_2022/WIP_best_insertion.ipynb#W6sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m    -- truck \u001b[39m\u001b[39m{\u001b[39;00mt_key1\u001b[39m}\u001b[39;00m\u001b[39m max_workhr is [\u001b[39m\u001b[39m{\u001b[39;00mtruck_list[t_key1][\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m] \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tan/Documents/GitHub/pdpt_2022/WIP_best_insertion.ipynb#W6sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m         manal_break_for_insepction()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tan/Documents/GitHub/pdpt_2022/WIP_best_insertion.ipynb#W6sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39mfor\u001b[39;00m i_ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(route_after)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)[::]:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tan/Documents/GitHub/pdpt_2022/WIP_best_insertion.ipynb#W6sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     A_, Ab_ \u001b[39m=\u001b[39m A_sol_file\u001b[39m.\u001b[39mcopy(), Ab_sol_file\u001b[39m.\u001b[39mcopy()\n",
      "\u001b[1;32m/home/tan/Documents/GitHub/pdpt_2022/WIP_best_insertion.ipynb Cell 8\u001b[0m in \u001b[0;36mmanal_break_for_insepction\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tan/Documents/GitHub/pdpt_2022/WIP_best_insertion.ipynb#W6sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmanal_break_for_insepction\u001b[39m():\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tan/Documents/GitHub/pdpt_2022/WIP_best_insertion.ipynb#W6sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     abc \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tan/Documents/GitHub/pdpt_2022/WIP_best_insertion.ipynb#W6sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39massert\u001b[39;00m abc\u001b[39m==\u001b[39m\u001b[39m2\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "truck_list = pdpt_ins1['truck']\n",
    "cargo_list = pdpt_ins1['cargo']\n",
    "constant = pdpt_ins1['constant']\n",
    "loading_coe = constant['loading_variation_coefficient']\n",
    "\n",
    "edge_shortest = pdpt_ins1['edge_shortest']\n",
    "undelivered_cargos = [key for key, value in cargo_route_file.items() if len(value)==0]\n",
    "\n",
    "for cargo_key in [undelivered_cargos[0],]:\n",
    "    common_nodes = {}\n",
    "    print(f'Cargo [{cargo_key}] is not delivered, we consider it for best_insertion')\n",
    "    # cargo['nb_cargo'] = ['size', 'lb_time', 'ub_time', 'departure_node', 'arrival_node']\n",
    "    c_size, c_lb_time, c_ub_time, c_origin, c_dest = cargo_list[cargo_key]\n",
    "\n",
    "    sorted_truck_list_ = sorted_truck_list[cargo_key]\n",
    "    for idx1 in range(len(sorted_truck_list_)):\n",
    "        t_key1 = sorted_truck_list_[idx1]\n",
    "        for idx2 in range(len(sorted_truck_list_)):\n",
    "            t_key2 = sorted_truck_list_[idx2]\n",
    "            intersect = set(truck_route_file[t_key1]).intersection(set(truck_route_file[t_key2]))\n",
    "            if t_key1 != t_key2 and len(intersect) > 0:\n",
    "                #  and set(truck_route_file[t_key1])==set(truck_route_file[t_key2]):\n",
    "                print(f'   truck[{t_key1}] route {truck_route_file[t_key1]}')\n",
    "                print(f'   truck[{t_key2}] route {truck_route_file[t_key2]}')\n",
    "                common_nodes[(t_key1, t_key2)] = list(intersect)\n",
    "                print(f'   common nodes are {intersect}')\n",
    "\n",
    "                for node_ in intersect:\n",
    "                    if node_ != truck_list[t_key1][0] and node_ != truck_list[t_key1][1]:\n",
    "                        print(f'\\tfind a common node [{node_}] that is not a origin or destination of truck')\n",
    "\n",
    "                        # try_best_insertion()\n",
    "                        idx_ = truck_route_file[t_key1].index(node_)\n",
    "                        route_before, route_after = truck_route_file[t_key1][:idx_+1], truck_route_file[t_key1][idx_:]\n",
    "                        print(truck_route_file[t_key1], route_before, route_after)\n",
    "                        for i_ in range(len(route_before)-1)[::-1]:\n",
    "                            A_, Ab_ = A_sol_file.copy(), Ab_sol_file.copy()\n",
    "                            D_, Db_ = D_sol_file.copy(), Db_sol_file.copy()\n",
    "                            S_, Sb_ = S_sol_file.copy(), Sb_sol_file.copy()\n",
    "\n",
    "                            node_curr = route_before[i_]\n",
    "                            node_next = route_before[i_+1]\n",
    "                            # # check capacity\n",
    "                            # print(f'\\t   Checking capacity constraints')\n",
    "                            # print(f'\\t    -- total size of cargos leave {node_curr} is [{S_[(node_curr, t_key1)]}]')\n",
    "                            # print(f'\\t    -- available capacity is {truck_list[t_key1][-1] - S_[(node_curr, t_key1)]}')\n",
    "                            # print(f'\\t    -- cargo size capacity is {c_size}')\n",
    "\n",
    "                            # if truck_list[t_key1][-1] - S_[(node_curr, t_key1)] > c_size:\n",
    "                            #     print(f'\\t    -- truck capacity constraint satisfied')\n",
    "                                \n",
    "\n",
    "                            if checking_capacity_constraints(node_curr, S_, truck_list, t_key1, c_size ) == True:\n",
    "\n",
    "                            #insert between curr and next nodes\n",
    "                                print(f'\\t    -- leave [{node_curr}] at {D_[(node_curr, t_key1)]}')\n",
    "                                print(f'\\t    -- edge_shortest from {node_curr} to origin of cargo {cargo_key} at {c_origin} is {edge_shortest[(node_curr, c_origin)]}')\n",
    "                            # # print(A_)\n",
    "                            # A_[node_curr] = \n",
    "                            \n",
    "                                manal_break_for_insepction()\n",
    "                        for i_ in range(len(route_after)-1)[::]:\n",
    "                            A_, Ab_ = A_sol_file.copy(), Ab_sol_file.copy()\n",
    "                            D_, Db_ = D_sol_file.copy(), Db_sol_file.copy()\n",
    "                            S_, Sb_ = S_sol_file.copy(), Sb_sol_file.copy()\n",
    "\n",
    "                            node_curr = route_after[i_]\n",
    "                            node_next = route_after[i_+1]\n",
    "\n",
    "                            if checking_capacity_constraints(node_curr, S_, truck_list, t_key1, c_size ) == True:\n",
    "\n",
    "                                print(f'\\t   Checking work time constraints')\n",
    "                                print(f'\\t    -- leave [{node_curr}] at {D_[(node_curr, t_key1)]}')\n",
    "                                print(f'\\t    -- edge_shortest from {node_curr} to origin of cargo {cargo_key} at {c_origin} is {edge_shortest[(node_curr, c_origin)]}')\n",
    "                                print(f'\\t    -- arrive cargo origin [{c_origin}] at {D_[(node_curr, t_key1)] + edge_shortest[(node_curr, c_origin)]}')\n",
    "                                A_[(c_origin, t_key1)] = D_[(node_curr, t_key1)] + edge_shortest[(node_curr, c_origin)]\n",
    "                                print(f'\\t    -- leaving cargo origin [{c_origin}] at {A_[(c_origin, t_key1)] + int(np.ceil(c_size*loading_coe))}')\n",
    "                                D_[(c_origin, t_key1)] = A_[(c_origin, t_key1)] + int(np.ceil(c_size*loading_coe))\n",
    "                                print(f'\\t    -- original arrival time the next node [{node_next}] at {A_[(node_next, t_key1)]}')\n",
    "                                print(f'\\t    -- entering the next node [{node_next}] at {D_[(c_origin, t_key1)] + edge_shortest[(c_origin, node_next)]}')\n",
    "                                cost = D_[(c_origin, t_key1)] + edge_shortest[(c_origin, node_next)] - A_[(node_next, t_key1)]\n",
    "\n",
    "                                print(f'\\t    -- departure the dest node of truck {t_key1} [{truck_list[t_key1][1]}] at {D_[(truck_list[t_key1][1], t_key1)] + cost}')\n",
    "                                print(f'\\t    -- truck {t_key1} max_workhr is [{truck_list[t_key1][-2]}] ')\n",
    "\n",
    "\n",
    "                            # # check capacity\n",
    "                            # print(f'total size of cargos leave {node_curr} is [{S_[(node_curr, t_key1)]}]')\n",
    "                            # print(f'available capacity is {truck_list[t_key1][-1] - S_[(node_curr, t_key1)]}')\n",
    "                            # print(f'cargo size capacity is {c_size}')\n",
    "\n",
    "                            # if truck_list[t_key1][-1] - S_[(node_curr, t_key1)] > c_size:\n",
    "                            #     print(f'truck capacity constraint satisfied')\n",
    "                                manal_break_for_insepction()\n",
    "                            # # for node in truck_route_file[t_key1]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4], [3], [2], [1], [0]]\n"
     ]
    }
   ],
   "source": [
    "print([[i] for i in range(0, 5)[::-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1990874c5d43c5ad255fb4eddb2910398111b9d51d69584c4b5152ab9b533bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
