{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>This notebook studies the <b>Team Orienteering </b> with Pick-up, Delivery Problem and Transfer (TOPDPT)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, random, time, pickle\n",
    "src_dir_ = '/home/tan/Documents/GitHub/pdpt_2022/src'\n",
    "sys.path.insert(1, src_dir_)\n",
    "\n",
    "from gurobipy import Model, quicksum, GRB\n",
    "import numpy as np\n",
    "from util import generate_node_cargo_size_change, read_pickle, group_cycle_truck, manual_stop\n",
    "from pathlib import Path\n",
    "from tvopdpt import tvopdpt_milp_gurobi\n",
    "dir_ = '/home/tan/Documents/GitHub/pdpt_2022/'\n",
    "num_ins = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_tvopdpt_mip(ins,  # dict contains the data of pdpt instance,\n",
    "                     gurobi_log_file, # file where all data of pdotw solutions are saved\n",
    "                     optimize_pdotw_routes = True,\n",
    "                     max_runtime = 100,\n",
    "                     verbose = 0):  \n",
    "\n",
    "    # load data from ins\n",
    "    selected_truck = ins['truck']\n",
    "    selected_cargo = ins['cargo']\n",
    "    selected_node = ins['nodes']\n",
    "    selected_edge = ins['edge_shortest']    \n",
    "    # edges = ins['edges']\n",
    "    # nodes = ins['nodes']\n",
    "    constant = ins['constant']\n",
    "    node_cargo_size_change = ins['node_cargo_size_change']\n",
    "    # path_shortest = ins['path_shortest']\n",
    "    single_truck_deviation = ins['single_truck_deviation']\n",
    "\n",
    "\n",
    "    # edge_shortest, path_shortest = replace_edge_by_shortest_length_nx(nodes, edges)\n",
    "    # single_truck_deviation = calculate_single_truck_deviation(truck, cargo, edge_shortest)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(f'========= START [PDOTW with truck ========= ')\n",
    "\n",
    "    \n",
    "    created_truck = selected_truck.copy()\n",
    "    \n",
    "    # nodes in the cluster\n",
    "    # Note. cargo['nb_cargo'] = ['size', 'lb_time', 'ub_time','departure_node', 'arrival_node']\n",
    "    # truck['nb_truck'] = ['departure_node', 'arrival_node', 'max_worktime', 'max_capacity']\n",
    "    \n",
    "\n",
    "    if verbose >0:\n",
    "        print(f'+++ Preprocess data to instantiate a PDOTW MIP')\n",
    "    if verbose > 2:\n",
    "        print(f'    [selected_cargo] size: {len(selected_cargo)}')\n",
    "        for key, value in selected_cargo.items():\n",
    "            print(f'        {key, value}')\n",
    "        print(f'    [created_truck] size: {len(created_truck)}')\n",
    "        for key, value in created_truck.items():\n",
    "            print(f'       {key, value}')\n",
    "    \n",
    "    ### Need to update node_cargo_size_change \n",
    "    node_cargo_size_change = generate_node_cargo_size_change(selected_node, selected_cargo)\n",
    "\n",
    "    ### group cycle and non-cycle trucks\n",
    "    created_truck_yCycle, created_truck_nCycle, selected_truck = group_cycle_truck(created_truck)  \n",
    "    \n",
    "    if verbose > 2:\n",
    "        print('    [created_truck_yCycle]', created_truck_yCycle)\n",
    "        print('    [created_truck_nCycle]', created_truck_nCycle)\n",
    "\n",
    "\n",
    "    if verbose >0:\n",
    "        print(f'+++ Solve TVOPDPT MILP in Gurobi')\n",
    "    ### use gurobi to solve the GROW origin PDPTW\n",
    "    # Note. the pdotw_mip_gurobi function is desgined to take the same arguments as pdpt function\n",
    "    # but some parameters\n",
    "\n",
    "\n",
    "\n",
    "    obj_val_MP, runtime_MP, gurobi_res = tvopdpt_milp_gurobi(constant, \n",
    "                                                           selected_cargo, \n",
    "                                                           selected_truck, \n",
    "                                                           created_truck_yCycle, \n",
    "                                                           created_truck_nCycle,\n",
    "                                                           selected_node, \n",
    "                                                           selected_edge, \n",
    "                                                           node_cargo_size_change, \n",
    "                                                           max_runtime, \n",
    "                                                           gurobi_log_file, \n",
    "                                                           verbose = 1)\n",
    "\n",
    "\n",
    "    x_sol, z_sol, u_sol, w_sol, S_sol, D_sol, A_sol, Sb_sol, Db_sol, Ab_sol = gurobi_res\n",
    "    # Index k for truck is pre-defined\n",
    "    #x_sol: x^k_{ij}, if truck k visit edge (i,j) or not\n",
    "    #z_sol: z^{kr}_{ij}, if truck k visit edge (i,j) with cargo r\n",
    "    #u_sol: u^r_i, if cargo r is transfered at node i\n",
    "    #y_sol: y^k_r, if parcel r is carried by truck k\n",
    "    #S_sol: x^k_i, total size of cargos on truck k at node i\n",
    "    #D_sol: D^k_i, depature time of truck k at node i\n",
    "    #A_sol: A^k_i, arrival time of truck k at node i\n",
    "\n",
    "    print(f'=== Result: total cargo [{len(selected_cargo.keys())}], MIP obj [{obj_val_MP}]')\n",
    "    res = {'obj_val_MP': obj_val_MP,\n",
    "           'runtime_MP': runtime_MP,\n",
    "           'x_sol':  x_sol,\n",
    "           'z_sol':  z_sol,\n",
    "           'u_sol':  u_sol,\n",
    "           'w_sol':  w_sol,\n",
    "           'S_sol':  S_sol,\n",
    "           'D_sol':  D_sol,\n",
    "           'A_sol':  A_sol,\n",
    "           'Sb_sol': Sb_sol,\n",
    "           'Db_sol': Db_sol,\n",
    "           'Ab_sol': Ab_sol\n",
    "          }\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== START team orienteering pdpt\n",
      "      /home/tan/Documents/GitHub/pdpt_2022/data/case1/case1_truck2_ins1.pkl\n",
      "========= START [PDOTW with truck ========= \n",
      "Set parameter Heuristics to value 0.5\n",
      "Set parameter LogFile to value \"/home/tan/Documents/GitHub/pdpt_2022/data/case1/tvopdpt_res/case1_truck2_ins1_gurobi.pkl\"\n",
      "9\n",
      "+++ Gurobi MIP for TVOPDPT [Feasible] \n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    max_runtime = 20\n",
    "    case_num, num_trucks = 1, 2\n",
    "\n",
    "    for ins_idx in range(10):\n",
    "        pdpt_ins_filename = os.path.join(dir_, f'data/case{case_num}', f'case{case_num}_truck{num_trucks}_ins{ins_idx+1}.pkl')\n",
    "        print(f'===== START team orienteering pdpt\\n      {pdpt_ins_filename}')\n",
    "        pdpt_ins = read_pickle(pdpt_ins_filename)\n",
    "\n",
    "        path_ = os.path.join(dir_, f'data/case{case_num}', 'tvopdpt_res')\n",
    "        Path(path_).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        gurobi_log_file = os.path.join(path_, f'case{case_num}_truck{num_trucks}_ins{ins_idx+1}_gurobi.pkl')\n",
    "\n",
    "        res = solve_tvopdpt_mip(pdpt_ins,  # dict contains the data of pdpt instance,\n",
    "                            gurobi_log_file, # file where all data of pdotw solutions are saved\n",
    "                            optimize_pdotw_routes = True,\n",
    "                            max_runtime = max_runtime,\n",
    "                            verbose = 0)\n",
    "\n",
    "        res_filename = os.path.join(path_, f'case{case_num}_truck{num_trucks}_ins{ins_idx+1}_res.pkl')\n",
    "        with open(res_filename, 'wb') as f:\n",
    "            pickle.dump(res, f)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== START team orienteering pdpt\n",
      "      /home/tan/Documents/GitHub/pdpt_2022/data/case1/case1_truck2_ins1.pkl\n",
      "total num. of cargo 16\n",
      "dict_keys(['obj_val_MP', 'runtime_MP', 'x_sol', 'z_sol', 'u_sol', 'w_sol', 'S_sol', 'D_sol', 'A_sol', 'Sb_sol', 'Db_sol', 'Ab_sol'])\n",
      "1\n",
      "4\n",
      "obj 14.0\n",
      "runtime_MP 100.00699710845947\n",
      "[C44], origin [N5], dest [N4]\n",
      "[C44] is not delivered\n",
      "[C89], origin [N10], dest [N15]\n",
      "  +++ C89 from origin [N10] to node [N15] by Truck T5\n",
      "[C108], origin [N5], dest [N4]\n",
      "  +++ C108 from origin [N5] to node [N10] by Truck T5\n",
      "  +++ C108 from node [N10] to node [N15] by Truck T5\n",
      "  +++ C108 from node [N15] to dest [N4] by Truck T5\n",
      "[C128], origin [N10], dest [N15]\n",
      "  +++ C128 from origin [N10] to node [N15] by Truck T5\n",
      "[C214], origin [N10], dest [N15]\n",
      "  +++ C214 from origin [N10] to node [N15] by Truck T5\n",
      "[C243], origin [N10], dest [N15]\n",
      "  +++ C243 from origin [N10] to node [N15] by Truck T5\n",
      "[C1], origin [N7], dest [N22]\n",
      "  +++ C1 from origin [N7] to node [N27] by Truck T21\n",
      "  +++ C1 from node [N27] to dest [N22] by Truck T21\n",
      "[C27], origin [N7], dest [N27]\n",
      "  +++ C27 from origin [N7] to node [N27] by Truck T21\n",
      "[C52], origin [N11], dest [N27]\n",
      "  +++ C52 from origin [N11] to node [N7] by Truck T21\n",
      "  +++ C52 from node [N7] to dest [N27] by Truck T21\n",
      "[C57], origin [N11], dest [N27]\n",
      "  +++ C57 from origin [N11] to node [N7] by Truck T21\n",
      "  +++ C57 from node [N7] to dest [N27] by Truck T21\n",
      "[C62], origin [N11], dest [N16]\n",
      "  +++ C62 from origin [N11] to node [N7] by Truck T21\n",
      "  +++ C62 from node [N7] to node [N27] by Truck T21\n",
      "  +++ C62 from node [N27] to node [N22] by Truck T21\n",
      "  +++ C62 from node [N22] to dest [N16] by Truck T21\n",
      "[C75], origin [N5], dest [N16]\n",
      "[C75] is not delivered\n",
      "[C179], origin [N7], dest [N29]\n",
      "  +++ C179 from origin [N7] to node [N27] by Truck T21\n",
      "  +++ C179 from node [N27] to node [N22] by Truck T21\n",
      "  +++ C179 from node [N22] to node [N16] by Truck T21\n",
      "  +++ C179 from node [N16] to dest [N29] by Truck T21\n",
      "[C182], origin [N7], dest [N16]\n",
      "  +++ C182 from origin [N7] to node [N27] by Truck T21\n",
      "  +++ C182 from node [N27] to node [N22] by Truck T21\n",
      "  +++ C182 from node [N22] to dest [N16] by Truck T21\n",
      "[C189], origin [N7], dest [N27]\n",
      "  +++ C189 from origin [N7] to node [N27] by Truck T21\n",
      "[C211], origin [N11], dest [N27]\n",
      "  +++ C211 from origin [N11] to node [N7] by Truck T21\n",
      "  +++ C211 from node [N7] to dest [N27] by Truck T21\n",
      "14 cargo delivered: ['C89', 'C108', 'C128', 'C214', 'C243', 'C1', 'C27', 'C52', 'C57', 'C62', 'C179', 'C182', 'C189', 'C211']\n",
      "2 cargo undelivered: ['C44', 'C75']\n"
     ]
    }
   ],
   "source": [
    "def check_mip_sol():\n",
    "    case_num, ins_idx, num_trucks = 1, 0, 2\n",
    "    pdpt_ins_filename = os.path.join(dir_, f'data/case{case_num}', f'case{case_num}_truck{num_trucks}_ins{ins_idx+1}.pkl')\n",
    "    print(f'===== START team orienteering pdpt\\n      {pdpt_ins_filename}')\n",
    "    pdpt_ins = read_pickle(pdpt_ins_filename)\n",
    "\n",
    "\n",
    "    # load data from ins\n",
    "    selected_truck = pdpt_ins['truck']\n",
    "    selected_cargo = pdpt_ins['cargo']\n",
    "    selected_node = pdpt_ins['nodes']\n",
    "    selected_edge = pdpt_ins['edge_shortest']    \n",
    "    # edges = ins['edges']\n",
    "    # nodes = ins['nodes']\n",
    "    constant = pdpt_ins['constant']\n",
    "    node_cargo_size_change = pdpt_ins['node_cargo_size_change']\n",
    "    edge_shortest = pdpt_ins['edge_shortest']\n",
    "    # path_shortest = ins['path_shortest']\n",
    "    single_truck_deviation = pdpt_ins['single_truck_deviation']\n",
    "\n",
    "    print(f'total num. of cargo {len(selected_cargo.keys())}')\n",
    "\n",
    "    tvopdpt_res_filename = os.path.join(dir_, f'data/case{case_num}', f'case{case_num}_truck{num_trucks}_ins{ins_idx+1}_res.pkl')\n",
    "    tvopdpt_res = read_pickle(tvopdpt_res_filename)\n",
    "\n",
    "    print(tvopdpt_res.keys())\n",
    "\n",
    "    print(sum(tvopdpt_res['u_sol'].values()))\n",
    "    print(sum(tvopdpt_res['w_sol'].values()))\n",
    "\n",
    "    print('obj', tvopdpt_res['obj_val_MP'])\n",
    "    print('runtime_MP', tvopdpt_res['runtime_MP'])\n",
    "    z_sol = tvopdpt_res['z_sol']\n",
    "\n",
    "    # truck1, truck2 = selected_truck.keys()\n",
    "    cargo_delivered = []\n",
    "    cargo_undelivered = []\n",
    "    for cargo_key, cargo_value in selected_cargo.items():\n",
    "        cargo_origin, cargo_dest = cargo_value[-2:]\n",
    "        print(f'[{cargo_key}], origin [{cargo_origin}], dest [{cargo_dest}]')\n",
    "        if sum([sum([z_sol[(node, cargo_dest, truck_key, cargo_key)]for node in selected_node if node != cargo_dest]) for truck_key in selected_truck.keys()]) == 1:\n",
    "            cargo_delivered.append(cargo_key)\n",
    "            node_curr = cargo_origin\n",
    "            for node_next in selected_node:\n",
    "                z_temp = 0\n",
    "                if node_next!=node_curr:\n",
    "                    for truck_key in selected_truck.keys():\n",
    "                        z_temp += z_sol[(cargo_origin, node_next, truck_key, cargo_key)]\n",
    "                        if z_sol[(cargo_origin, node_next, truck_key, cargo_key)] == 1:\n",
    "                            print(f'  +++ {cargo_key} from origin [{node_curr}] to node [{node_next}] by Truck {truck_key}')\n",
    "                            node_curr = node_next\n",
    "                            \n",
    "                        if z_temp == 1:\n",
    "                            break\n",
    "                if z_temp == 1:\n",
    "                    break\n",
    "\n",
    "                    \n",
    "            while node_curr != cargo_dest:\n",
    "                z_temp = 0\n",
    "                for node_next in selected_node:\n",
    "                    if node_next!=node_curr:\n",
    "                        for truck_key in selected_truck.keys():\n",
    "                            z_temp += z_sol[(node_curr, node_next, truck_key, cargo_key)]\n",
    "                            if z_sol[(node_curr, node_next, truck_key, cargo_key)] == 1:\n",
    "                                if node_next == cargo_dest:\n",
    "                                    print(f'  +++ {cargo_key} from node [{node_curr}] to dest [{node_next}] by Truck {truck_key}')\n",
    "                                else:\n",
    "                                    print(f'  +++ {cargo_key} from node [{node_curr}] to node [{node_next}] by Truck {truck_key}')\n",
    "                                node_curr = node_next\n",
    "\n",
    "                                \n",
    "                            \n",
    "                            if z_temp == 1:\n",
    "                                break\n",
    "                    if z_temp == 1:\n",
    "                        break\n",
    "        else:\n",
    "            cargo_undelivered.append(cargo_key)\n",
    "\n",
    "            print(f'[{cargo_key}] is not delivered')\n",
    "\n",
    "    print(f'{len(cargo_delivered)} cargo delivered: {cargo_delivered}')\n",
    "    print(f'{len(cargo_undelivered)} cargo undelivered: {cargo_undelivered}')\n",
    "check_mip_sol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_pdpt_solution(pdpt_ins, tvopdpt_res, verbose = 0):\n",
    "\n",
    "    selected_cargo = pdpt_ins['cargo']\n",
    "    selected_truck = pdpt_ins['truck']\n",
    "    assert len(selected_truck.keys()) == 2\n",
    "    truck1, truck2 = selected_truck.keys()\n",
    "    selected_node  = pdpt_ins['nodes']\n",
    "    selected_edge  = pdpt_ins['edge_shortest']\n",
    "    \n",
    "    x_sol = tvopdpt_res['x_sol']\n",
    "    z_sol = tvopdpt_res['z_sol']\n",
    "    z_sol = tvopdpt_res['z_sol']\n",
    "    u_sol = tvopdpt_res['u_sol']\n",
    "    w_sol = tvopdpt_res['w_sol']\n",
    "\n",
    "    truck_used = []         # list of trucks used in the solution\n",
    "    \n",
    "    # dictionary, for each truck_key, there is a list of cargo carried that was on this truck. E.g., {'T1\": ['C1', 'C2', ...]}\n",
    "    cargo_in_truck = {}   \n",
    "    for truck_key in selected_truck.keys():\n",
    "        cargo_in_truck[truck_key] = []\n",
    "\n",
    "    # dictionary, for each cargo_key, there is a list of truck that carried this cargo. E.g., {'C1\": ['T1', 'T2', ...]}\n",
    "    trucks_per_cargo = {} \n",
    "    for cargo_key in selected_cargo.keys():\n",
    "        trucks_per_cargo[cargo_key] = []\n",
    "\n",
    "    cargo_delivered = []   # list of delivered cargo\n",
    "    cargo_undelivered = [] # list of undelivered cargo\n",
    "\n",
    "\n",
    "    truck_route = {}\n",
    "    for truck_key in selected_truck.keys():\n",
    "        truck_route[truck_key] = []\n",
    "    cargo_route = {}\n",
    "    for cargo_key in selected_cargo.keys():\n",
    "        cargo_route[cargo_key] = []\n",
    "\n",
    "    # dict, for each cargo_key, there is a nested list, each with [transfer_node, truck_from, truck_to]\n",
    "    cargo_transfer = {}\n",
    "    for cargo_key in selected_cargo.keys():\n",
    "        cargo_transfer[cargo_key] = []\n",
    "\n",
    "    if verbose >0:\n",
    "        print(f'   +++ Process cargo-to-truck-assignment')\n",
    "    # Generate cargo_in_truck\n",
    "    for cargo_key, cargo_value in selected_cargo.items():\n",
    "        cargo_origin, cargo_dest = cargo_value[-2:]\n",
    "        # assert sum([z_sol[(cargo_origin, node_, truck1, cargo_key)] for node_ in selected_node if node_!= cargo_origin]) + sum([z_sol[(cargo_origin, node_, truck2, cargo_key)] for node_ in selected_node if node_!= cargo_origin]) == 1\n",
    "        # assert sum([z_sol[(node_, cargo_dest, truck1, cargo_key)] for node_ in selected_node if node_!= cargo_dest]) +sum([z_sol[(cargo_dest, node_, truck2, cargo_key)] for node_ in selected_node if node_!= cargo_dest]) == 1\n",
    "\n",
    "        for truck_key in selected_truck.keys():\n",
    "            if sum([z_sol[(cargo_origin, node_, truck_key, cargo_key)] for node_ in selected_node if node_!= cargo_origin]) + sum([z_sol[(node_, cargo_dest, truck_key, cargo_key)] for node_ in selected_node if node_!= cargo_dest])  >=1:\n",
    "                cargo_in_truck[truck_key].append(cargo_key)\n",
    "\n",
    "\n",
    "    if verbose >0:\n",
    "        print(f'   +++ Process truck_route')\n",
    "    # postprocess truck_route\n",
    "    for truck_key in selected_truck:\n",
    "        source = selected_truck[truck_key][0] # starting from the origin node of each truck\n",
    "        for node_ in selected_node:\n",
    "            if node_ != source and x_sol[(source, node_, truck_key)] == 1: # find node_ such that x[source, node_, truck_key] == 1\n",
    "\n",
    "                if len(truck_route[truck_key]) == 0: # append source as the first node\n",
    "                        truck_route[truck_key].append(source)\n",
    "                truck_route[truck_key].append(node_)\n",
    "                source = node_\n",
    "                break\n",
    "        while source != selected_truck[truck_key][1]: # terminate when reach the arival node of each truck\n",
    "            for node_ in selected_node:\n",
    "                if node_ != source and x_sol[(source, node_, truck_key)] == 1: # find node_ such that x[source, node_, truck_key] == 1\n",
    "                    truck_route[truck_key].append(node_)\n",
    "                    source = node_\n",
    "                    break\n",
    "\n",
    "    # RECALL, cargo is a dictionary with the following format:\n",
    "    # cargo['nb_cargo'] = ['size', 'lb_time', 'ub_time', 'departure_node', 'arrival_node']\n",
    "\n",
    "    if verbose >0:\n",
    "        print(f'   +++ Process cargo_route, cargo_delivered and cargo_undelivered')\n",
    "    for cargo_key, cargo_value in selected_cargo.items():\n",
    "        cargo_origin, cargo_dest = cargo_value[-2:]\n",
    "        # if cargo is delivered\n",
    "        if sum([z_sol[(node_, cargo_dest, truck_key, cargo_key)] for node_ in selected_node for truck_key in selected_truck.keys() if node_!= cargo_dest]) == 1:\n",
    "            cargo_delivered.append(cargo_key)\n",
    "            print(f'cargo [{cargo_key}] is delivered')\n",
    "\n",
    "            #start from cargo_origin\n",
    "            node_curr = cargo_origin\n",
    "            #check the next node\n",
    "            for n_next in selected_node:\n",
    "                if n_next != node_curr:\n",
    "                    for truck_key in selected_truck.keys():\n",
    "                        if z_sol[(node_curr, n_next, truck_key, cargo_key)] == 1:\n",
    "                            if len(cargo_route[cargo_key]) == 0: # append source as the first node\n",
    "                                cargo_route[cargo_key].append((truck_key, node_curr))\n",
    "                            cargo_route[cargo_key].append((truck_key, n_next))\n",
    "                            node_curr = n_next\n",
    "                            print(f'cargo_origin [{cargo_origin}], node_next[{n_next}]')\n",
    "                            break\n",
    "\n",
    "            while node_curr != cargo_value[-1]:\n",
    "                for n_next in selected_node:\n",
    "                    if n_next!=node_curr:\n",
    "                        for truck_key in selected_truck.keys():\n",
    "                            if  z_sol[(node_curr, n_next, truck_key, cargo_key)] == 1:\n",
    "                                cargo_route[cargo_key].append((truck_key, n_next))\n",
    "                                node_curr = n_next\n",
    "                                break\n",
    " \n",
    "        else:\n",
    "            print([ [truck_key, cargo_key, sum(z_sol[(node_, cargo_dest, truck_key, cargo_key)] for node_ in selected_node if node_!= cargo_dest) ] for truck_key in selected_truck.keys()])\n",
    "\n",
    "            assert sum([z_sol[(node_, cargo_dest, truck_key, cargo_key)] for node_ in selected_node for truck_key in selected_truck.keys() if node_!= cargo_dest]) == 0\n",
    "            print(f'cargo [{cargo_key}] is undelivered')\n",
    "\n",
    "            cargo_undelivered.append(cargo_key)\n",
    "\n",
    "    truck_1, truck_2 = selected_truck.keys()\n",
    "    if verbose >0:\n",
    "        print(f'   +++ Process cargo_transfer')\n",
    "    for cargo_ in selected_cargo.keys():\n",
    "        for node_curr in selected_node:\n",
    "            if u_sol[node_, cargo_key] == 1:\n",
    "                assert sum([z_sol[(node_prev, node_curr, truck_1, cargo_)] for node_prev in selected_node if node_curr != node_prev]) - sum([z_sol[(node_curr, node_next, truck_2, cargo_)] for node_next in selected_node if node_curr != node_next]) == 1\n",
    "                cargo_transfer[cargo_key].append([node_curr, truck_1, truck_2])\n",
    "            if w_sol[node_curr, cargo_key] == 1:\n",
    "                assert sum([z_sol[(node_prev, node_curr, truck_2, cargo_)] for node_prev in selected_node]) - sum([z_sol[(node_curr, node_next, truck_1, cargo_)] for node_next in selected_node]) == 1\n",
    "                cargo_transfer[cargo_key].append([node_curr, truck_2, truck_1])\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "    processed_res = (truck_used, cargo_delivered, cargo_undelivered, cargo_in_truck, truck_route, cargo_route, cargo_transfer)\n",
    "\n",
    "\n",
    "    return processed_res\n",
    "\n",
    "\n",
    "def read_result():\n",
    "    case_num, ins_idx, num_trucks = 1, 0, 2\n",
    "    \n",
    "    pdpt_ins_filename = os.path.join(dir_, f'data/case{case_num}', f'case{case_num}_truck{num_trucks}_ins{ins_idx+1}.pkl')\n",
    "    pdpt_ins = read_pickle(pdpt_ins_filename)\n",
    "    \n",
    "    print('=== summary of pdpt_ins')\n",
    "    print('\\t[', len(pdpt_ins['cargo'].keys()),'] cargos, [', len(pdpt_ins['truck'].keys()),'] trucks')\n",
    "    res_filename = os.path.join(dir_, f'data/case{case_num}', f'case{case_num}_truck{num_trucks}_ins{ins_idx+1}_res.pkl')\n",
    "    tvopdpt_res = read_pickle(res_filename, verbose = 0) \n",
    "    print('=== Start Postprocess mip sol')\n",
    "    processed_res  = postprocess_pdpt_solution(pdpt_ins, tvopdpt_res, verbose = 1)\n",
    "    \n",
    "    truck_used, cargo_delivered, cargo_undelivered, trucks_per_cargo, cargo_in_truck, truck_route, cargo_route, cargo_transfer = processed_res\n",
    "\n",
    "    print(f'+++ list of cargos sucessfully delivered \\n{cargo_delivered}')\n",
    "          \n",
    "    print(cargo_undelivered)\n",
    "    \n",
    "read_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c1990874c5d43c5ad255fb4eddb2910398111b9d51d69584c4b5152ab9b533bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
