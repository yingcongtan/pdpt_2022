{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>This notebook studies the <b>Team Orienteering </b> with Pick-up, Delivery Problem and Transfer (TOPDPT)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, random, time, pickle\n",
    "src_dir_ = '/home/tan/Documents/GitHub/pdpt_2022/src'\n",
    "sys.path.insert(1, src_dir_)\n",
    "\n",
    "from gurobipy import Model, quicksum, GRB\n",
    "import numpy as np\n",
    "from util import generate_node_cargo_size_change, read_pickle, group_cycle_truck, manual_stop\n",
    "from pathlib import Path\n",
    "from tvopdpt import tvopdpt_milp_gurobi\n",
    "dir_ = '/home/tan/Documents/GitHub/pdpt_2022/'\n",
    "num_ins = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_pdotw_mip(ins,  # dict contains the data of pdpt instance,\n",
    "                    path_, # file where all data of pdotw solutions are saved\n",
    "                    optimize_pdotw_routes = True,\n",
    "                    max_runtime = 100,\n",
    "                    verbose = 0):  \n",
    "\n",
    "    # load data from ins\n",
    "    selected_truck = ins['truck']\n",
    "    selected_cargo = ins['cargo']\n",
    "    selected_node = ins['nodes']\n",
    "    selected_edge = ins['edge_shortest']    \n",
    "    # edges = ins['edges']\n",
    "    # nodes = ins['nodes']\n",
    "    constant = ins['constant']\n",
    "    node_cargo_size_change = ins['node_cargo_size_change']\n",
    "    edge_shortest = ins['edge_shortest']\n",
    "    # path_shortest = ins['path_shortest']\n",
    "    single_truck_deviation = ins['single_truck_deviation']\n",
    "\n",
    "\n",
    "    # edge_shortest, path_shortest = replace_edge_by_shortest_length_nx(nodes, edges)\n",
    "    # single_truck_deviation = calculate_single_truck_deviation(truck, cargo, edge_shortest)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(f'========= START [PDOTW with truck ========= ')\n",
    "\n",
    "    \n",
    "    created_truck = selected_truck.copy()\n",
    "    \n",
    "    # nodes in the cluster\n",
    "    # Note. cargo['nb_cargo'] = ['size', 'lb_time', 'ub_time','departure_node', 'arrival_node']\n",
    "    # truck['nb_truck'] = ['departure_node', 'arrival_node', 'max_worktime', 'max_capacity']\n",
    "    \n",
    "\n",
    "    if verbose >0:\n",
    "        print(f'+++ Preprocess data to instantiate a PDOTW MIP')\n",
    "    if verbose > 2:\n",
    "        print(f'    [selected_cargo] size: {len(selected_cargo)}')\n",
    "        for key, value in selected_cargo.items():\n",
    "            print(f'        {key, value}')\n",
    "        print(f'    [created_truck] size: {len(created_truck)}')\n",
    "        for key, value in created_truck.items():\n",
    "            print(f'       {key, value}')\n",
    "    \n",
    "    ### Need to update node_cargo_size_change \n",
    "    node_cargo_size_change = generate_node_cargo_size_change(selected_node, selected_cargo)\n",
    "\n",
    "    ### group cycle and non-cycle trucks\n",
    "    created_truck_yCycle, created_truck_nCycle, selected_truck = group_cycle_truck(created_truck)  \n",
    "    \n",
    "    if verbose > 2:\n",
    "        print('    [created_truck_yCycle]', created_truck_yCycle)\n",
    "        print('    [created_truck_nCycle]', created_truck_nCycle)\n",
    "\n",
    "\n",
    "    if verbose >0:\n",
    "        print(f'+++ Solve TVOPDPT MILP in Gurobi')\n",
    "    ### use gurobi to solve the GROW origin PDPTW\n",
    "    # Note. the pdotw_mip_gurobi function is desgined to take the same arguments as pdpt function\n",
    "    # but some parameters\n",
    "    gurobi_log_file = os.path.join(path_, f'_gurobi.log')\n",
    "\n",
    "\n",
    "    obj_val, model_runtime, milp_sol = tvopdpt_milp_gurobi(constant, \n",
    "                                                           selected_cargo, \n",
    "                                                           selected_truck, \n",
    "                                                           created_truck_yCycle, \n",
    "                                                           created_truck_nCycle,\n",
    "                                                           selected_node, \n",
    "                                                           selected_edge, \n",
    "                                                           node_cargo_size_change, \n",
    "                                                           max_runtime, \n",
    "                                                           gurobi_log_file, \n",
    "                                                           verbose = 1)\n",
    "\n",
    "    x_sol, z_sol, y_sol, S_sol, D_sol, A_sol, Sb_sol, Db_sol, Ab_sol, u_sol, w_sol = milp_sol\n",
    "    # Index k for truck is pre-defined\n",
    "    #x_sol: x^k_{ij}, if truck k visit edge (i,j) or not\n",
    "    #z_sol: z^{kr}_{ij}, if truck k visit edge (i,j) with cargo r\n",
    "    #u_sol: u^r_i, if cargo r is transfered at node i\n",
    "    #y_sol: y^k_r, if parcel r is carried by truck k\n",
    "    #S_sol: x^k_i, total size of cargos on truck k at node i\n",
    "    #D_sol: D^k_i, depature time of truck k at node i\n",
    "    #A_sol: A^k_i, arrival time of truck k at node i\n",
    "\n",
    "    res = {'x_sol':  x_sol,\n",
    "           'z_sol':  z_sol,\n",
    "           'y_sol':  y_sol,\n",
    "           'S_sol':  S_sol,\n",
    "           'D_sol':  D_sol,\n",
    "           'A_sol':  A_sol,\n",
    "           'Sb_sol': Sb_sol,\n",
    "           'Db_sol': Db_sol,\n",
    "           'Ab_sol': Ab_sol,\n",
    "           'u_sol':  u_sol,\n",
    "           'w_sol':  w_sol\n",
    "          }\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== START team orienteering pdpt\n",
      "      /home/tan/Documents/GitHub/pdpt_2022/data/case1/case1_truck2_ins1.pkl\n",
      "========= START [PDOTW with truck ========= \n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-09-15\n",
      "Set parameter Heuristics to value 0.5\n",
      "Set parameter LogFile to value \"/home/tan/Documents/GitHub/pdpt_2022/toy/top_pdpt/_gurobi.log\"\n",
      "9\n",
      "+++ Gurobi MIP for TVOPDPT [Feasible] \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(res_filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     18\u001b[0m         pickle\u001b[38;5;241m.\u001b[39mdump(res, f)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m path_ \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoy/top_pdpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m Path(path_)\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 10\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43msolve_pdotw_mip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdpt_ins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# dict contains the data of pdpt instance,\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mpath_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# file where all data of pdotw solutions are saved\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m                      \u001b[49m\u001b[43moptimize_pdotw_routes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mmax_runtime\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m res_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/case\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcase_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcase\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcase_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_truck\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_trucks\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_ins\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mins_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_res.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(res_filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36msolve_pdotw_mip\u001b[0;34m(ins, path_, optimize_pdotw_routes, max_runtime, verbose)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m### use gurobi to solve the GROW origin PDPTW\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Note. the pdotw_mip_gurobi function is desgined to take the same arguments as pdpt function\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# but some parameters\u001b[39;00m\n\u001b[1;32m     61\u001b[0m gurobi_log_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_gurobi.log\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m obj_val, model_runtime, milp_sol \u001b[38;5;241m=\u001b[39m tvopdpt_milp_gurobi(constant, \n\u001b[1;32m     65\u001b[0m                                                        selected_cargo, \n\u001b[1;32m     66\u001b[0m                                                        selected_truck, \n\u001b[1;32m     67\u001b[0m                                                        created_truck_yCycle, \n\u001b[1;32m     68\u001b[0m                                                        created_truck_nCycle,\n\u001b[1;32m     69\u001b[0m                                                        selected_node, \n\u001b[1;32m     70\u001b[0m                                                        selected_edge, \n\u001b[1;32m     71\u001b[0m                                                        node_cargo_size_change, \n\u001b[1;32m     72\u001b[0m                                                        max_runtime, \n\u001b[1;32m     73\u001b[0m                                                        gurobi_log_file, \n\u001b[1;32m     74\u001b[0m                                                        verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     76\u001b[0m x_sol, z_sol, y_sol, S_sol, D_sol, A_sol, Sb_sol, Db_sol, Ab_sol, u_sol, w_sol \u001b[38;5;241m=\u001b[39m milp_sol\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Index k for truck is pre-defined\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m#x_sol: x^k_{ij}, if truck k visit edge (i,j) or not\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m#z_sol: z^{kr}_{ij}, if truck k visit edge (i,j) with cargo r\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m#D_sol: D^k_i, depature time of truck k at node i\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m#A_sol: A^k_i, arrival time of truck k at node i\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    case_num, ins_idx, num_trucks = 1, 0, 2\n",
    "    pdpt_ins_filename = os.path.join(dir_, f'data/case{case_num}', f'case{case_num}_truck{num_trucks}_ins{ins_idx+1}.pkl')\n",
    "    print(f'===== START team orienteering pdpt\\n      {pdpt_ins_filename}')\n",
    "    pdpt_ins = read_pickle(pdpt_ins_filename)\n",
    "\n",
    "\n",
    "    path_ = os.path.join(dir_, 'toy/top_pdpt')\n",
    "    Path(path_).mkdir(parents=True, exist_ok=True)\n",
    "    res = solve_pdotw_mip(pdpt_ins,  # dict contains the data of pdpt instance,\n",
    "                          path_, # file where all data of pdotw solutions are saved\n",
    "                          optimize_pdotw_routes = True,\n",
    "                          max_runtime = 100,\n",
    "                          verbose = 0)\n",
    "\n",
    "    res_filename = os.path.join(dir_, f'data/case{case_num}', f'case{case_num}_truck{num_trucks}_ins{ins_idx+1}_res.pkl')\n",
    "    with open(res_filename, 'wb') as f:\n",
    "        pickle.dump(res, f)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_pdpt_solution(pdpt_ins, tvopdpt_res, verbose = 0):\n",
    "\n",
    "    selected_cargo = pdpt_ins['cargo']\n",
    "    selected_truck = pdpt_ins['truck']\n",
    "    selected_node  = pdpt_ins['nodes']\n",
    "    selected_edge  = pdpt_ins['edge_shortest']\n",
    "    \n",
    "    x_sol = tvopdpt_res['x_sol']\n",
    "    y_sol = tvopdpt_res['y_sol']\n",
    "    z_sol = tvopdpt_res['z_sol']\n",
    "    u_sol = tvopdpt_res['u_sol']\n",
    "    w_sol = tvopdpt_res['w_sol']\n",
    "\n",
    "    truck_used = []         # list of trucks used in the solution\n",
    "    \n",
    "    # dictionary, for each truck_key, there is a list of cargo carried that was on this truck. E.g., {'T1\": ['C1', 'C2', ...]}\n",
    "    cargo_in_truck = {}   \n",
    "    for truck_key in selected_truck.keys():\n",
    "        cargo_in_truck[truck_key] = []\n",
    "\n",
    "    # dictionary, for each cargo_key, there is a list of truck that carried this cargo. E.g., {'C1\": ['T1', 'T2', ...]}\n",
    "    trucks_per_cargo = {} \n",
    "    for cargo_key in selected_cargo.keys():\n",
    "        trucks_per_cargo[cargo_key] = []\n",
    "\n",
    "    cargo_delivered = []   # list of delivered cargo\n",
    "    cargo_undelivered = [] # list of undelivered cargo\n",
    "\n",
    "\n",
    "    truck_route = {}\n",
    "    for truck_key in selected_truck.keys():\n",
    "        truck_route[truck_key] = []\n",
    "    cargo_route = {}\n",
    "    for cargo_key in selected_cargo.keys():\n",
    "        cargo_route[cargo_key] = []\n",
    "\n",
    "    # dict, for each cargo_key, there is a nested list, each with [transfer_node, truck_from, truck_to]\n",
    "    cargo_transfer = {}\n",
    "    for cargo_key in selected_cargo.keys():\n",
    "        cargo_transfer[cargo_key] = []\n",
    "\n",
    "    # postprocess cargo_in_truck and truck_used\n",
    "    for truck_key in selected_truck:\n",
    "        truck_used_flag = 0\n",
    "        # Generate cargo_in_truck\n",
    "        for cargo_key in selected_cargo.keys():\n",
    "            if y_sol[(truck_key, cargo_key)] == 1:\n",
    "                if verbose > 0: \n",
    "                    print('    The cargo {} has been carried by truck {}'.format(cargo_key, truck_key))\n",
    "                truck_used_flag += 1\n",
    "                cargo_in_truck[truck_key].append(cargo_key)\n",
    "        if truck_used_flag > 0:\n",
    "            \n",
    "            # put the truck_key into used trucks\n",
    "            truck_used.append(truck_key)\n",
    "\n",
    "    # postprocess truck_route\n",
    "    for truck_key in selected_truck:\n",
    "        source = selected_truck[truck_key][0] # starting from the origin node of each truck\n",
    "        for node_ in selected_node:\n",
    "            if node_ != source and x_sol[(source, node_, truck_key)] == 1: # find node_ such that x[source, node_, truck_key] == 1\n",
    "\n",
    "                if len(truck_route[truck_key]) == 0: # append source as the first node\n",
    "                        truck_route[truck_key].append(source)\n",
    "                truck_route[truck_key].append(node_)\n",
    "                source = node_\n",
    "                break\n",
    "        while source != selected_truck[truck_key][1]: # terminate when reach the arival node of each truck\n",
    "            for node_ in selected_node:\n",
    "                if node_ != source and x_sol[(source, node_, truck_key)] == 1: # find node_ such that x[source, node_, truck_key] == 1\n",
    "                    truck_route[truck_key].append(node_)\n",
    "                    source = node_\n",
    "                    break\n",
    "\n",
    "    # RECALL, cargo is a dictionary with the following format:\n",
    "    # cargo['nb_cargo'] = ['size', 'lb_time', 'ub_time', 'departure_node', 'arrival_node']\n",
    "\n",
    "    for cargo_key, cargo_value in selected_cargo.items():\n",
    "        dest = cargo_value[-1]\n",
    "        if sum([z_sol[(node_, dest, truck_key, cargo_key)] for node_ in selected_node for truck_key in selected_truck.keys() if node_!= dest]) == 1:\n",
    "            assert sum([y_sol[(truck_, cargo_key)] for truck_ in selected_truck]) == 1\n",
    "            cargo_delivered.append(cargo_key)\n",
    "            truck_list = [truck_key for truck_key in selected_truck.keys()  # list of truck_key\n",
    "                                        if y_sol[(truck_key, cargo_key)]  == 1  ]# if cargo_key is carried by truck_key i.e., y^k_r == 1\n",
    "            n_curr = cargo_value[3]\n",
    "            for n_next in selected_node:\n",
    "                for truck_key in truck_list:\n",
    "                    if n_next!=n_curr and z_sol[(n_curr, n_next, truck_key, cargo_key)] == 1:\n",
    "                        if len(cargo_route[cargo_key]) == 0: # append source as the first node\n",
    "                            cargo_route[cargo_key].append((truck_key, n_curr))\n",
    "                        cargo_route[cargo_key].append((truck_key, n_next))\n",
    "                        n_curr = n_next\n",
    "                        break\n",
    "                else:\n",
    "                    continue\n",
    "                break\n",
    "            while n_curr != cargo_value[-1]:\n",
    "                for n_next in selected_node:\n",
    "                    for truck_key in truck_list:\n",
    "                        if n_next!=n_curr and z_sol[(n_curr, n_next, truck_key, cargo_key)] == 1:\n",
    "                            cargo_route[cargo_key].append((truck_key, n_next))\n",
    "                            n_curr = n_next\n",
    "                            break\n",
    "                    else:\n",
    "                        continue\n",
    "                    break\n",
    "        else:\n",
    "            print([ [truck_key, cargo_key, sum(z_sol[(node_, dest, truck_key, cargo_key)] for node_ in selected_node if node_!= dest) ] for truck_key in selected_truck.keys()])\n",
    "\n",
    "            assert sum([y_sol[(truck_, cargo_key)] for truck_ in selected_truck]) == 0, [[(truck_, cargo_key), y_sol[(truck_, cargo_key)]] for truck_ in selected_truck]\n",
    "            cargo_undelivered.append(cargo_key)\n",
    "    truck_1, truck_2 = selected_truck.keys()\n",
    "    \n",
    "    for cargo_ in selected_cargo.keys():\n",
    "        for node_ in selected_node:\n",
    "            if u_sol[node_, cargo_key] == 1:\n",
    "#                 print(sum([z_sol[(node_prev, node_, truck_1, cargo_)] for node_prev in selected_node]))\n",
    "#                 print(sum([z_sol[(node_, node_next, truck_2, cargo_)] for node_next in selected_node]))\n",
    "                assert sum([z_sol[(node_prev, node_, truck_1, cargo_)] for node_prev in selected_node]) - sum([z_sol[(node_, node_next, truck_2, cargo_)] for node_next in selected_node]) == 1\n",
    "                cargo_transfer[(node_, cargo_key)] = [node_, truck_1, truck_2]\n",
    "            if w_sol[node_, cargo_key] == 1:\n",
    "                assert sum([z_sol[(node_prev, node_, truck_2, cargo_)] for node_prev in selected_node]) - sum([z_sol[(node_, node_next, truck_1, cargo_)] for node_next in selected_node]) == 1\n",
    "                cargo_transfer[(node_, cargo_key)] = [node_, truck_2, truck_1]\n",
    "                \n",
    "\n",
    "    trucks_per_cargo = {cargo_key: [truck_key  for truck_key in selected_truck.keys() if y_sol[(truck_key, cargo_key)]==1 ] for cargo_key, cargo_value in selected_cargo.items()}\n",
    "\n",
    "\n",
    "    processed_res = (truck_used, cargo_delivered, cargo_undelivered, trucks_per_cargo, cargo_in_truck, truck_route, cargo_route, cargo_transfer)\n",
    "\n",
    "\n",
    "    return processed_res\n",
    "\n",
    "\n",
    "def read_result():\n",
    "    case_num, ins_idx, num_trucks = 1, 0, 2\n",
    "    \n",
    "    pdpt_ins_filename = os.path.join(dir_, f'data/case{case_num}', f'case{case_num}_truck{num_trucks}_ins{ins_idx+1}.pkl')\n",
    "    pdpt_ins = read_pickle(pdpt_ins_filename)\n",
    "    \n",
    "    print('=== summary of pdpt_ins')\n",
    "    \n",
    "    print('[', len(pdpt_ins['cargo'].keys()),'] cargos, [', len(pdpt_ins['truck'].keys()),'] trucks')\n",
    "    res_filename = os.path.join(dir_, f'data/case{case_num}', f'case{case_num}_truck{num_trucks}_ins{ins_idx+1}_res.pkl')\n",
    "    tvopdpt_res = read_pickle(res_filename, verbose = 0) \n",
    "    processed_res  = postprocess_pdpt_solution(pdpt_ins, tvopdpt_res, verbose = 0)\n",
    "    \n",
    "    truck_used, cargo_delivered, cargo_undelivered, trucks_per_cargo, cargo_in_truck, truck_route, cargo_route, cargo_transfer = processed_res\n",
    "\n",
    "    print(f'+++ list of cargos sucessfully delivered \\n{cargo_delivered}')\n",
    "          \n",
    "    print(cargo_undelivered)\n",
    "    \n",
    "read_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>How to encode transfer in TOPDPT ?</h3>\n",
    "\n",
    "Here we consider a simple case of only two trucks $k_1, k_2$.\n",
    "\n",
    "On top of the single-vehicle Pick-up Delivery Orienteering Problem with Time-Window (PDOTW), we introduce two sets of new variables $z^{kr}_{ij}, u^r_i \\in \\{0,1\\}$.\n",
    "\n",
    "We add constraints to encode the following situations. \n",
    "\n",
    "$$\\text{from Jason's code}\\left\\{\\begin{aligned} \n",
    "&\\sum_{i\\in\\mathcal{V}}u^r_i,\\;  \\forall <= 1 &&\\text{each cargo } r \\text{ can only be transfered at most once}\\\\\n",
    "&u^r_i >= \\sum_{j\\in\\mathcal{V}: j\\neq i}z^{kr}_{ij} - \\sum_{j\\in\\mathcal{V}: j\\neq i}z^{kr}_{ji},\\; \\forall i\\in\\mathcal{V}, r, k && u^r_i = 1 \\text{ IFF } \\underbrace{\\sum_{j\\in\\mathcal{V}: j\\neq i}z^{kr}_{ij} = 1}_{\\text{ truck }k \\text{ arrives node } i \\text{ with cargo }r } \\text{ and } \\underbrace{\\sum_{j\\in\\mathcal{V}: j\\neq i}z^{kr}_{ji}}_{\\text{ truck }k \\text{ leaves node } i \\text{ without cargo }r }\n",
    "\\end{aligned}\\right.$$\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "&\\text{Does not consider transfer}\\\\\n",
    "&DT^k_i \\ge AT^k_i + \\underbrace{\\text{fixed time} + \\text{load pick-up cargos} + \\text{unload delivery cargos}}_{\\text{time that } k \\text{ spends on node } i\\text{, these terms are independent of cargo transfer}}, \\; k\\in\\{k_1,k_2\\}, i\\in\\mathcal{V}\\\\ \\\\\n",
    "&\\text{let } T^k = \\text{fixed time} + \\text{load pick-up cargos} + \\text{unload delivery cargos} \\\\ \\\\\n",
    "&\\text{Consider transfer from }k_2 \\text{ to } k_1\\\\\n",
    "&\\quad \\text{1. if } k_2 \\text{ finishes unloading transfer cargos before the arrival of } k_1, \\\\\n",
    "&\\quad \\text{that is, } AT^{k_2}_i + \\text{unload }r \\le AT^{k_1}_i\\\\\n",
    "&\\quad DT^{k_1}_i \\ge AT^{k_1}_i + \\underbrace{\\text{load }r}_{\\forall u^r_i=1} + T^{k_1}\\\\\n",
    "&\\quad\\quad\\quad\\quad - M\\Big(2 - u^r_i - \\sum_{j\\in\\mathcal{j}:\\:j\\neq i} z^{k_1r}_{ij}\\Big) , \\; \\forall i\\in\\mathcal{V}, r\n",
    "\\\\ \\\\\n",
    "&\\quad \\text{2. if } k_2 \\text{ after } k_1 \\text{ and before } k_1 \\text{ finished everything} \\\\\n",
    "&\\quad \\text{that is, } AT^{k_1}_i \\le AT^{k_2}_i \\le AT^{k_1}_i + T^{k_1}\\\\\n",
    "&\\quad DT^{k_1}_i \\ge AT^{k_1}_i + \\underbrace{\\text{unload and load}r}_{\\forall u^r_i=1}   + T\\\\\n",
    "&\\quad\\quad\\quad\\quad - M\\Big(2 - u^r_i - \\sum_{j\\in\\mathcal{j}:\\:j\\neq i} z^{k_1r}_{ij}\\Big) , \\; \\forall i\\in\\mathcal{V}, r \\\\ \\\\\n",
    "&\\quad \\text{3. if } k_2 \\text{ arrives after } k_1 \\text{ finished everything} \\\\\n",
    "&\\quad \\text{that is, } AT^{k_2}_i \\ge AT^{k_1}_i + T^{k_1}\\\\\n",
    "&\\quad DT^{k_1}_i \\ge AT^{k_2}_i + \\underbrace{\\text{unload and load}r}_{\\forall u^r_i=1}   + T\\\\\n",
    "&\\quad\\quad\\quad\\quad - M\\Big(2 - u^r_i - \\sum_{j\\in\\mathcal{j}:\\:j\\neq i} z^{k_1r}_{ij}\\Big) , \\; \\forall i\\in\\mathcal{V}, r\n",
    "\\end{aligned}\n",
    "\n",
    "the last two constraints are controled by Big-M, it is active IFF $\\underbrace{u^r_r = 1}_{ r \\text{ is transfered at } i}$ and $\\underbrace{\\sum_{j\\in\\mathcal{j}:\\:j\\neq i} z^{kr}_{ij}=1}_{r \\text{ is not carried by }k_1 \\text{ when arrives at } i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*[[]]*11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c1990874c5d43c5ad255fb4eddb2910398111b9d51d69584c4b5152ab9b533bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
