{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>This notebook studies the <b>Team Orienteering </b> with Pick-up, Delivery Problem and Transfer (TOPDPT)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, random, time, pickle\n",
    "src_dir_ = '/home/tan/Documents/GitHub/pdpt_2022/src'\n",
    "sys.path.insert(1, src_dir_)\n",
    "\n",
    "from gurobipy import Model, quicksum, GRB\n",
    "import numpy as np\n",
    "from util import generate_node_cargo_size_change, read_pickle, group_cycle_truck, manual_stop\n",
    "from pathlib import Path\n",
    "from tvopdpt import tvopdpt_milp_gurobi\n",
    "dir_ = '/home/tan/Documents/GitHub/pdpt_2022/'\n",
    "num_ins = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_tvopdpt_mip(ins,  # dict contains the data of pdpt instance,\n",
    "                     gurobi_log_file, # file where all data of pdotw solutions are saved\n",
    "                     optimize_pdotw_routes = True,\n",
    "                     max_runtime = 100,\n",
    "                     verbose = 0):  \n",
    "\n",
    "    # load data from ins\n",
    "    selected_truck = ins['truck']\n",
    "    selected_cargo = ins['cargo']\n",
    "    selected_node = ins['nodes']\n",
    "    selected_edge = ins['edge_shortest']    \n",
    "    # edges = ins['edges']\n",
    "    # nodes = ins['nodes']\n",
    "    constant = ins['constant']\n",
    "    node_cargo_size_change = ins['node_cargo_size_change']\n",
    "    # path_shortest = ins['path_shortest']\n",
    "    single_truck_deviation = ins['single_truck_deviation']\n",
    "    \n",
    "    print(f'========= START TVOPDPT =========')\n",
    "    print(f'   +++ with [{len(selected_truck.keys())}] Truck {list(selected_truck.keys())}  ')\n",
    "\n",
    "    print(f'   +++ with [{len(selected_cargo.keys())}] cargo {list(selected_cargo.keys())}  ')\n",
    "    print(f'   +++ with [{len(selected_node)}] cargo {selected_node}  ')\n",
    "\n",
    "    \n",
    "\n",
    "    # edge_shortest, path_shortest = replace_edge_by_shortest_length_nx(nodes, edges)\n",
    "    # single_truck_deviation = calculate_single_truck_deviation(truck, cargo, edge_shortest)\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "    created_truck = selected_truck.copy()\n",
    "    \n",
    "    # nodes in the cluster\n",
    "    # Note. cargo['nb_cargo'] = ['size', 'lb_time', 'ub_time','departure_node', 'arrival_node']\n",
    "    # truck['nb_truck'] = ['departure_node', 'arrival_node', 'max_worktime', 'max_capacity']\n",
    "    \n",
    "\n",
    "    if verbose >0:\n",
    "        print(f'+++ Preprocess data to instantiate a PDOTW MIP')\n",
    "    if verbose > 2:\n",
    "        print(f'    [selected_cargo] size: {len(selected_cargo)}')\n",
    "        for key, value in selected_cargo.items():\n",
    "            print(f'        {key, value}')\n",
    "        print(f'    [created_truck] size: {len(created_truck)}')\n",
    "        for key, value in created_truck.items():\n",
    "            print(f'       {key, value}')\n",
    "    \n",
    "    ### Need to update node_cargo_size_change \n",
    "    node_cargo_size_change = generate_node_cargo_size_change(selected_node, selected_cargo)\n",
    "\n",
    "    ### group cycle and non-cycle trucks\n",
    "    created_truck_yCycle, created_truck_nCycle, selected_truck = group_cycle_truck(created_truck)  \n",
    "    \n",
    "    if verbose > 2:\n",
    "        print('    [created_truck_yCycle]', created_truck_yCycle)\n",
    "        print('    [created_truck_nCycle]', created_truck_nCycle)\n",
    "\n",
    "\n",
    "    if verbose >0:\n",
    "        print(f'+++ Solve TVOPDPT MILP in Gurobi')\n",
    "    ### use gurobi to solve the GROW origin PDPTW\n",
    "    # Note. the pdotw_mip_gurobi function is desgined to take the same arguments as pdpt function\n",
    "    # but some parameters\n",
    "\n",
    "    obj_val_MP, runtime_MP, gurobi_res = tvopdpt_milp_gurobi(constant, \n",
    "                                                           selected_cargo, \n",
    "                                                           selected_truck, \n",
    "                                                           created_truck_yCycle, \n",
    "                                                           created_truck_nCycle,\n",
    "                                                           selected_node, \n",
    "                                                           selected_edge, \n",
    "                                                           node_cargo_size_change, \n",
    "                                                           max_runtime, \n",
    "                                                           gurobi_log_file, \n",
    "                                                           verbose = 1)\n",
    "\n",
    "    x_sol, z_sol, u_sol, w_sol, S_sol, D_sol, A_sol, Sb_sol, Db_sol, Ab_sol = gurobi_res\n",
    "    # Index k for truck is pre-defined\n",
    "    #x_sol: x^k_{ij}, if truck k visit edge (i,j) or not\n",
    "    #z_sol: z^{kr}_{ij}, if truck k visit edge (i,j) with cargo r\n",
    "    #u_sol: u^r_i, if cargo r is transfered at node i\n",
    "    #y_sol: y^k_r, if parcel r is carried by truck k\n",
    "    #S_sol: x^k_i, total size of cargos on truck k at node i\n",
    "    #D_sol: D^k_i, depature time of truck k at node i\n",
    "    #A_sol: A^k_i, arrival time of truck k at node i\n",
    "\n",
    "    print(f'=== Result: total cargo [{len(selected_cargo.keys())}], MIP obj [{obj_val_MP}]')\n",
    "    res = {'obj_val_MP': obj_val_MP,\n",
    "           'runtime_MP': runtime_MP,\n",
    "           'x_sol':  x_sol,\n",
    "           'z_sol':  z_sol,\n",
    "           'u_sol':  u_sol,\n",
    "           'w_sol':  w_sol,\n",
    "           'S_sol':  S_sol,\n",
    "           'D_sol':  D_sol,\n",
    "           'A_sol':  A_sol,\n",
    "           'Sb_sol': Sb_sol,\n",
    "           'Db_sol': Db_sol,\n",
    "           'Ab_sol': Ab_sol\n",
    "          }\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== START team orienteering pdpt\n",
      "      /home/tan/Documents/GitHub/pdpt_2022/out/subproblem.pkl\n",
      "========= START TVOPDPT =========\n",
      "   +++ with [2] Truck ['T7', 'T19']  \n",
      "   +++ with [15] cargo ['C99', 'C71', 'C105', 'C137', 'C161', 'C58', 'C60', 'C62', 'C87', 'C90', 'C95', 'C102', 'C130', 'C135', 'C173']  \n",
      "   +++ with [11] cargo ['N8', 'N18', 'N15', 'N9', 'N10', 'N5', 'N4', 'N3', 'N11', 'N23', 'N25']  \n",
      "dict_keys(['T7', 'T19'])\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-09-15\n",
      "Set parameter Heuristics to value 0.5\n",
      "Set parameter LogFile to value \"/home/tan/Documents/GitHub/pdpt_2022/out/subproblem_gurobi.pkl\"\n",
      "Set parameter TimeLimit to value 100\n",
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "Optimize a model with 6398 rows, 3916 columns and 33775 nonzeros\n",
      "Model fingerprint: 0x120f91b6\n",
      "Variable types: 0 continuous, 3916 integer (3850 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+04]\n",
      "  RHS range        [1e+00, 4e+03]\n",
      "Presolve removed 2873 rows and 1554 columns\n",
      "Presolve time: 0.04s\n",
      "Presolved: 3525 rows, 2362 columns, 19383 nonzeros\n",
      "Variable types: 0 continuous, 2362 integer (2302 binary)\n",
      "Found heuristic solution: objective -0.0000000\n",
      "\n",
      "Root relaxation: objective 1.500000e+01, 2479 iterations, 0.13 seconds (0.25 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0   15.00000    0   18   -0.00000   15.00000      -     -    0s\n",
      "H    0     0                       2.0000000   15.00000   650%     -    0s\n",
      "     0     0   15.00000    0  197    2.00000   15.00000   650%     -    0s\n",
      "H    0     0                       7.0000000   15.00000   114%     -    0s\n",
      "     0     0   15.00000    0   60    7.00000   15.00000   114%     -    0s\n",
      "H    0     0                       9.0000000   15.00000  66.7%     -    0s\n",
      "     0     0   15.00000    0   63    9.00000   15.00000  66.7%     -    0s\n",
      "     0     0   15.00000    0   87    9.00000   15.00000  66.7%     -    1s\n",
      "     0     0   15.00000    0   89    9.00000   15.00000  66.7%     -    1s\n",
      "     0     0   15.00000    0   84    9.00000   15.00000  66.7%     -    1s\n",
      "     0     0   15.00000    0  117    9.00000   15.00000  66.7%     -    1s\n",
      "     0     0   15.00000    0   53    9.00000   15.00000  66.7%     -    1s\n",
      "H    0     0                      10.0000000   15.00000  50.0%     -    1s\n",
      "     0     0   15.00000    0   75   10.00000   15.00000  50.0%     -    1s\n",
      "     0     0   15.00000    0   72   10.00000   15.00000  50.0%     -    1s\n",
      "     0     0   15.00000    0   72   10.00000   15.00000  50.0%     -    1s\n",
      "     0     2   15.00000    0   70   10.00000   15.00000  50.0%     -    1s\n",
      "H   35    40                      11.0000000   15.00000  36.4%   263    2s\n",
      "H   78   100                      12.0000000   15.00000  25.0%   226    2s\n",
      "   747   644 infeasible   32        12.00000   15.00000  25.0%   114    5s\n",
      "  2288  1236   15.00000   16   12   12.00000   15.00000  25.0%   113   10s\n",
      "  2369  1295   15.00000   23  139   12.00000   15.00000  25.0%   114   15s\n",
      "H 2446  1270                      13.0000000   15.00000  15.4%   131   19s\n",
      "  2453  1381   15.00000   25   89   13.00000   15.00000  15.4%   133   23s\n",
      "  2579  1581   15.00000   29   94   13.00000   15.00000  15.4%   161   26s\n",
      "  2899  1648 infeasible   35        13.00000   15.00000  15.4%   174   31s\n",
      "  3151  1988   15.00000   70  154   13.00000   15.00000  15.4%   201   39s\n",
      "  3843  2288   15.00000   95  106   13.00000   15.00000  15.4%   242   50s\n",
      "  4846  2352   15.00000   31  127   13.00000   15.00000  15.4%   254   62s\n",
      "  5656  2619   15.00000   50  169   13.00000   15.00000  15.4%   271   73s\n",
      "  6897  2968   14.97188   56  167   13.00000   15.00000  15.4%   299   85s\n",
      "  7575  3762   14.97188   58  189   13.00000   15.00000  15.4%   325   98s\n",
      "  9261  3786   15.00000   46   85   13.00000   15.00000  15.4%   333  100s\n",
      "\n",
      "Cutting planes:\n",
      "  Cover: 5\n",
      "  Implied bound: 12\n",
      "  Clique: 2\n",
      "  StrongCG: 1\n",
      "  Flow cover: 7\n",
      "  GUB cover: 2\n",
      "  Zero half: 1\n",
      "  RLT: 12\n",
      "  Relax-and-lift: 8\n",
      "\n",
      "Explored 9329 nodes (3113851 simplex iterations) in 100.03 seconds (112.84 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 8: 13 12 11 ... -0\n",
      "\n",
      "Time limit reached\n",
      "Best objective 1.300000000000e+01, best bound 1.500000000000e+01, gap 15.3846%\n",
      "9\n",
      "+++ Gurobi MIP for TVOPDPT [Feasible] \n",
      "=== Result: total cargo [15], MIP obj [13.0]\n"
     ]
    }
   ],
   "source": [
    "def test_subproblem():\n",
    "    max_runtime = 100\n",
    "    case_num, num_trucks = 1, 2\n",
    "\n",
    "    for ins_idx in range(1):\n",
    "        pdpt_ins_filename = os.path.join(dir_, 'out', 'subproblem.pkl')\n",
    "        print(f'===== START team orienteering pdpt\\n      {pdpt_ins_filename}')\n",
    "        pdpt_ins = read_pickle(pdpt_ins_filename)\n",
    "\n",
    "        path_ = os.path.join(dir_, f'data/case{case_num}', 'tvopdpt_res')\n",
    "        Path(path_).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        gurobi_log_file = os.path.join(dir_, 'out', 'subproblem_gurobi.pkl')\n",
    "\n",
    "        res = solve_tvopdpt_mip(pdpt_ins,  # dict contains the data of pdpt instance,\n",
    "                            gurobi_log_file, # file where all data of pdotw solutions are saved\n",
    "                            optimize_pdotw_routes = True,\n",
    "                            max_runtime = max_runtime,\n",
    "                            verbose = 0)\n",
    "\n",
    "        res_filename = os.path.join(dir_, 'out', 'subproblem_res.pkl')\n",
    "        with open(res_filename, 'wb') as f:\n",
    "            pickle.dump(res, f)\n",
    "test_subproblem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== START team orienteering pdpt\n",
      "      /home/tan/Documents/GitHub/pdpt_2022/data/case1/case1_truck2_ins1.pkl\n",
      "========= START TVOPDPT =========\n",
      "   +++ with [2] Truck ['T5', 'T21']  \n",
      "   +++ with [16] cargo ['C44', 'C89', 'C108', 'C128', 'C214', 'C243', 'C1', 'C27', 'C52', 'C57', 'C62', 'C75', 'C179', 'C182', 'C189', 'C211']  \n",
      "   +++ with [10] cargo ['N5', 'N4', 'N10', 'N15', 'N11', 'N29', 'N7', 'N22', 'N27', 'N16']  \n",
      "dict_keys(['T5', 'T21'])\n",
      "Set parameter Heuristics to value 0.5\n",
      "Set parameter LogFile to value \"/home/tan/Documents/GitHub/pdpt_2022/data/case1/tvopdpt_res/case1_truck2_ins1_gurobi.pkl\"\n",
      "Set parameter TimeLimit to value 100\n",
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "Optimize a model with 5662 rows, 3440 columns and 29918 nonzeros\n",
      "Model fingerprint: 0x6b9add4e\n",
      "Variable types: 0 continuous, 3440 integer (3380 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+04]\n",
      "  RHS range        [1e+00, 4e+03]\n",
      "Found heuristic solution: objective -0.0000000\n",
      "Presolve removed 2730 rows and 1459 columns\n",
      "Presolve time: 0.03s\n",
      "Presolved: 2932 rows, 1981 columns, 16486 nonzeros\n",
      "Variable types: 0 continuous, 1981 integer (1926 binary)\n",
      "\n",
      "Root relaxation: objective 1.600000e+01, 1222 iterations, 0.04 seconds (0.06 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0   16.00000    0  106   -0.00000   16.00000      -     -    0s\n",
      "H    0     0                       8.0000000   16.00000   100%     -    0s\n",
      "     0     0   16.00000    0  211    8.00000   16.00000   100%     -    0s\n",
      "     0     0   16.00000    0  205    8.00000   16.00000   100%     -    0s\n",
      "     0     0   16.00000    0  124    8.00000   16.00000   100%     -    0s\n",
      "     0     0   16.00000    0  129    8.00000   16.00000   100%     -    0s\n",
      "     0     0   16.00000    0  150    8.00000   16.00000   100%     -    0s\n",
      "     0     0   16.00000    0  160    8.00000   16.00000   100%     -    0s\n",
      "     0     0   16.00000    0  112    8.00000   16.00000   100%     -    1s\n",
      "H    0     0                       9.0000000   16.00000  77.8%     -    1s\n",
      "     0     0   16.00000    0  100    9.00000   16.00000  77.8%     -    1s\n",
      "     0     0   16.00000    0  121    9.00000   16.00000  77.8%     -    1s\n",
      "     0     0   16.00000    0  146    9.00000   16.00000  77.8%     -    1s\n",
      "     0     0   16.00000    0   46    9.00000   16.00000  77.8%     -    1s\n",
      "     0     0   16.00000    0   45    9.00000   16.00000  77.8%     -    1s\n",
      "     0     0   16.00000    0   33    9.00000   16.00000  77.8%     -    1s\n",
      "     0     0   16.00000    0  121    9.00000   16.00000  77.8%     -    1s\n",
      "     0     0   16.00000    0   88    9.00000   16.00000  77.8%     -    1s\n",
      "     0     0   16.00000    0   88    9.00000   16.00000  77.8%     -    1s\n",
      "H    0     0                      10.0000000   16.00000  60.0%     -    2s\n",
      "     0     2   16.00000    0   88   10.00000   16.00000  60.0%     -    2s\n",
      "H   67    70                      11.0000000   16.00000  45.5%   164    2s\n",
      "H  527   428                      14.0000000   16.00000  14.3%  64.6    4s\n",
      "  1956   720   15.72968   66  173   14.00000   16.00000  14.3%  56.8    6s\n",
      "  3742  1194   16.00000   27  123   14.00000   16.00000  14.3%  58.9   10s\n",
      "  3834  1266   16.00000   15  131   14.00000   16.00000  14.3%  68.2   16s\n",
      "  3959  1332   16.00000   19   92   14.00000   16.00000  14.3%  76.5   21s\n",
      "  4154  1631   16.00000   21  174   14.00000   16.00000  14.3%  84.9   27s\n",
      "  4522  1834   16.00000   23  123   14.00000   16.00000  14.3%  95.4   32s\n",
      "  5104  2305   16.00000   32  155   14.00000   16.00000  14.3%   123   41s\n",
      "  6272  4696   16.00000   34  157   14.00000   16.00000  14.3%   152   47s\n",
      " 10617  4427   15.50000  107  199   14.00000   16.00000  14.3%   130   50s\n",
      " 11305  4833 infeasible   38        14.00000   16.00000  14.3%   137   58s\n",
      " 11780  5113   16.00000   37   96   14.00000   16.00000  14.3%   141   63s\n",
      " 12194  5252   16.00000   72  176   14.00000   16.00000  14.3%   148   68s\n",
      " 12449  5439   15.00000   83  187   14.00000   16.00000  14.3%   152   73s\n",
      " 12878  5751   16.00000   32  161   14.00000   16.00000  14.3%   155   77s\n",
      " 13410  6012   15.63912  124  216   14.00000   16.00000  14.3%   159   82s\n",
      " 13979  6034   16.00000   43  148   14.00000   16.00000  14.3%   161   89s\n",
      " 14023  6298   16.00000   45  149   14.00000   16.00000  14.3%   162   94s\n",
      " 14630  6438   16.00000   61  102   14.00000   16.00000  14.3%   167  100s\n",
      "\n",
      "Cutting planes:\n",
      "  Lift-and-project: 2\n",
      "  Cover: 10\n",
      "  Clique: 2\n",
      "  Flow cover: 3\n",
      "  Zero half: 1\n",
      "  RLT: 5\n",
      "\n",
      "Explored 14902 nodes (2521568 simplex iterations) in 100.01 seconds (100.98 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 6: 14 11 10 ... -0\n",
      "\n",
      "Time limit reached\n",
      "Best objective 1.400000000000e+01, best bound 1.600000000000e+01, gap 14.2857%\n",
      "9\n",
      "+++ Gurobi MIP for TVOPDPT [Feasible] \n",
      "=== Result: total cargo [16], MIP obj [14.0]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    max_runtime = 100\n",
    "    case_num, num_trucks = 1, 2\n",
    "\n",
    "    for ins_idx in range(1):\n",
    "        pdpt_ins_filename = os.path.join(dir_, f'data/case{case_num}', f'case{case_num}_truck{num_trucks}_ins{ins_idx+1}.pkl')\n",
    "        print(f'===== START team orienteering pdpt\\n      {pdpt_ins_filename}')\n",
    "        pdpt_ins = read_pickle(pdpt_ins_filename)\n",
    "\n",
    "        path_ = os.path.join(dir_, f'data/case{case_num}', 'tvopdpt_res')\n",
    "        Path(path_).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        gurobi_log_file = os.path.join(path_, f'case{case_num}_truck{num_trucks}_ins{ins_idx+1}_gurobi.pkl')\n",
    "\n",
    "        res = solve_tvopdpt_mip(pdpt_ins,  # dict contains the data of pdpt instance,\n",
    "                            gurobi_log_file, # file where all data of pdotw solutions are saved\n",
    "                            optimize_pdotw_routes = True,\n",
    "                            max_runtime = max_runtime,\n",
    "                            verbose = 0)\n",
    "\n",
    "        res_filename = os.path.join(path_, f'case{case_num}_truck{num_trucks}_ins{ins_idx+1}_res.pkl')\n",
    "        with open(res_filename, 'wb') as f:\n",
    "            pickle.dump(res, f)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== START team orienteering pdpt\n",
      "      /home/tan/Documents/GitHub/pdpt_2022/out/subproblem.pkl\n",
      "['N8', 'N18', 'N15', 'N9', 'N10', 'N5', 'N4', 'N3', 'N11', 'N23', 'N25']\n",
      "total num. of cargo 15\n",
      "dict_keys(['obj_val_MP', 'runtime_MP', 'x_sol', 'z_sol', 'u_sol', 'w_sol', 'S_sol', 'D_sol', 'A_sol', 'Sb_sol', 'Db_sol', 'Ab_sol'])\n",
      "obj 13.0\n",
      "runtime_MP 100.0383551120758\n",
      "=== Check transfer\n",
      "=== truck route\n",
      " +++ [T7], origin [N8], dest [N18]\n",
      "  ++++++ T7 from origin [N8] to node [N5]\n",
      "  ++++++ T7 from node [N5] to node [N4]\n",
      "  ++++++ T7 from node [N4] to node [N25]\n",
      "  ++++++ T7 from node [N25] to node [N11]\n",
      "  ++++++ T7 from node [N11] to dest [N18]\n",
      " +++ [T19], origin [N8], dest [N15]\n",
      "  ++++++ T19 from origin [N8] to node [N9]\n",
      "  ++++++ T19 from node [N9] to node [N5]\n",
      "  ++++++ T19 from node [N5] to node [N18]\n",
      "  ++++++ T19 from node [N18] to node [N23]\n",
      "  ++++++ T19 from node [N23] to node [N11]\n",
      "  ++++++ T19 from node [N11] to dest [N15]\n",
      "s_sol[(N8, T7)] 4159\n",
      "sum_z * size 4159\n",
      "s_sol[(N8, T19)] 3797\n",
      "sum_z * size 3797\n",
      "s_sol[(N18, T19)] 5705\n",
      "sum_z * size 5705\n",
      "s_sol[(N15, T7)] 0\n",
      "sum_z * size 0\n",
      "s_sol[(N9, T7)] 0\n",
      "sum_z * size 0\n",
      "s_sol[(N9, T19)] 6542\n",
      "sum_z * size 6542\n",
      "s_sol[(N10, T7)] 0\n",
      "sum_z * size 0\n",
      "s_sol[(N10, T19)] 0\n",
      "sum_z * size 0\n",
      "s_sol[(N5, T7)] 4399\n",
      "sum_z * size 4399\n",
      "s_sol[(N5, T19)] 5705\n",
      "sum_z * size 5705\n",
      "s_sol[(N4, T7)] 4154\n",
      "sum_z * size 4154\n",
      "s_sol[(N4, T19)] 0\n",
      "sum_z * size 0\n",
      "s_sol[(N3, T7)] 0\n",
      "sum_z * size 0\n",
      "s_sol[(N3, T19)] 0\n",
      "sum_z * size 0\n",
      "s_sol[(N11, T7)] 0\n",
      "sum_z * size 0\n",
      "s_sol[(N11, T19)] 0\n",
      "sum_z * size 0\n",
      "s_sol[(N23, T7)] 0\n",
      "sum_z * size 0\n",
      "s_sol[(N23, T19)] 1058\n",
      "sum_z * size 1058\n",
      "s_sol[(N25, T7)] 0\n",
      "sum_z * size 0\n",
      "s_sol[(N25, T19)] 0\n",
      "sum_z * size 0\n"
     ]
    }
   ],
   "source": [
    "def check_mip_sol():\n",
    "    case_num, ins_idx, num_trucks = 1, 0, 2\n",
    "#     pdpt_ins_filename = os.path.join(dir_, f'data/case{case_num}', f'case{case_num}_truck{num_trucks}_ins{ins_idx+1}.pkl')\n",
    "    pdpt_ins_filename = os.path.join(dir_, 'out', 'subproblem.pkl')\n",
    "\n",
    "    print(f'===== START team orienteering pdpt\\n      {pdpt_ins_filename}')\n",
    "    pdpt_ins = read_pickle(pdpt_ins_filename)\n",
    "\n",
    "\n",
    "    # load data from ins\n",
    "    selected_truck = pdpt_ins['truck']\n",
    "    selected_cargo = pdpt_ins['cargo']\n",
    "    selected_node = pdpt_ins['nodes']\n",
    "    print(selected_node)\n",
    "    selected_edge = pdpt_ins['edge_shortest']    \n",
    "    # edges = ins['edges']\n",
    "    # nodes = ins['nodes']\n",
    "    constant = pdpt_ins['constant']\n",
    "    node_cargo_size_change = pdpt_ins['node_cargo_size_change']\n",
    "    edge_shortest = pdpt_ins['edge_shortest']\n",
    "    # path_shortest = ins['path_shortest']\n",
    "    single_truck_deviation = pdpt_ins['single_truck_deviation']\n",
    "\n",
    "    print(f'total num. of cargo {len(selected_cargo.keys())}')\n",
    "\n",
    "#     tvopdpt_res_filename = os.path.join(dir_, f'data/case{case_num}/tvopdpt_res', f'case{case_num}_truck{num_trucks}_ins{ins_idx+1}_res.pkl')\n",
    "    tvopdpt_res_filename = os.path.join(dir_, 'out', 'subproblem_res.pkl')\n",
    "    tvopdpt_res = read_pickle(tvopdpt_res_filename)\n",
    "\n",
    "    print(tvopdpt_res.keys())\n",
    "\n",
    "\n",
    "    print('obj', tvopdpt_res['obj_val_MP'])\n",
    "    print('runtime_MP', tvopdpt_res['runtime_MP'])\n",
    "    z_sol = tvopdpt_res['z_sol']\n",
    "    u_sol = tvopdpt_res['u_sol']\n",
    "    w_sol = tvopdpt_res['w_sol']\n",
    "    x_sol = tvopdpt_res['x_sol']\n",
    "    s_sol = tvopdpt_res['S_sol']\n",
    "\n",
    "    print('=== Check transfer')\n",
    "    truck_1, truck_2 = selected_truck.keys()\n",
    "    for cargo_key, cargo_value in selected_cargo.items():\n",
    "        cargo_origin, cargo_destination = cargo_value[-2], cargo_value[-1]\n",
    "        for node_ in selected_node:\n",
    "            if w_sol[(node_, cargo_key)] == 1:\n",
    "                print(f' +++ {cargo_key} is transferred from Truck [{truck_2}] to Truck [{truck_1}] at node [{node_}]')\n",
    "            if u_sol[(node_, cargo_key)] == 1:\n",
    "                print(f' +++ {cargo_key} is transferred from Truck [{truck_1}] to Truck [{truck_2}] at node [{node_}]')\n",
    "\n",
    "    print('=== truck route')\n",
    "\n",
    "    for truck_key in selected_truck:\n",
    "        truck_origin, truck_des = selected_truck[truck_key][:2] # starting from the origin node of each truck\n",
    "        print(f' +++ [{truck_key}], origin [{truck_origin}], dest [{truck_des}]')\n",
    "        node_curr = truck_origin\n",
    "        for node_ in selected_node:\n",
    "            if node_ != node_curr and x_sol[(node_curr, node_, truck_key)] == 1: # find node_ such that x[source, node_, truck_key] == 1\n",
    "                print(f'  ++++++ {truck_key} from origin [{node_curr}] to node [{node_}]')\n",
    "#                 print(f'  ++++++ s_sol[({node_}, {truck_key})]: [{s_sol[(node_, truck_key)]}]')\n",
    "                node_curr = node_\n",
    "                break\n",
    "        while node_curr != selected_truck[truck_key][1]: # terminate when reach the arival node of each truck\n",
    "            for node_ in selected_node:\n",
    "                if node_ != node_curr and x_sol[(node_curr, node_, truck_key)] == 1: # find node_ such that x[source, node_, truck_key] == 1\n",
    "                    if node_ == truck_des:\n",
    "                        print(f'  ++++++ {truck_key} from node [{node_curr}] to dest [{node_}]')\n",
    "                    else:\n",
    "                        print(f'  ++++++ {truck_key} from node [{node_curr}] to node [{node_}]')\n",
    "                            \n",
    "                    node_curr = node_\n",
    "                    break\n",
    "                    \n",
    "#     for node_curr in selected_node:\n",
    "#         for truck_key in selected_truck.keys():\n",
    "#             if node_curr !=  selected_truck[truck_key][1]:\n",
    "#                 print(f's_sol[({node_curr}, {truck_key})] {s_sol[(node_curr, truck_key)]}')\n",
    "#                 print(f'sum_z * size {sum([z_sol[(node_curr, node_next, truck_key, cargo_key)]* selected_cargo[cargo_key][0] for node_next in selected_node for cargo_key in selected_cargo.keys() if node_next != node_curr]) }')\n",
    "    \n",
    "    print('=== cargo route')\n",
    "\n",
    "    # truck1, truck2 = selected_truck.keys()\n",
    "    cargo_delivered = []\n",
    "    cargo_undelivered = []\n",
    "    for cargo_key, cargo_value in selected_cargo.items():\n",
    "        cargo_origin, cargo_dest = cargo_value[-2:]\n",
    "        print(f'   +++ [{cargo_key}], origin [{cargo_origin}], dest [{cargo_dest}]')\n",
    "        if sum([sum([z_sol[(node, cargo_dest, truck_key, cargo_key)]for node in selected_node if node != cargo_dest]) for truck_key in selected_truck.keys()]) == 1:\n",
    "            cargo_delivered.append(cargo_key)\n",
    "            node_curr = cargo_origin\n",
    "            for node_next in selected_node:\n",
    "                z_temp = 0\n",
    "                if node_next!=node_curr:\n",
    "                    for truck_key in selected_truck.keys():\n",
    "                        z_temp += z_sol[(cargo_origin, node_next, truck_key, cargo_key)]\n",
    "                        if z_sol[(cargo_origin, node_next, truck_key, cargo_key)] == 1:\n",
    "                            print(f'  ++++++ {cargo_key} from origin [{node_curr}] to node [{node_next}] by Truck {truck_key}')\n",
    "                            print(f'  ++++++ z_sol[({cargo_origin}, {node_next}, {truck_key}, {cargo_key})] = {z_sol[(cargo_origin, node_next, truck_key, cargo_key)]}' )\n",
    "                            node_curr = node_next\n",
    "                            \n",
    "                        if z_temp == 1:\n",
    "                            break\n",
    "                if z_temp == 1:\n",
    "                    break\n",
    "            while node_curr != cargo_dest:\n",
    "                z_temp = 0\n",
    "                for node_next in selected_node:\n",
    "                    if node_next!=node_curr:node_next\n",
    "                        for truck_key in selected_truck.keys():\n",
    "                            z_temp += z_sol[(node_curr, node_next, truck_key, cargo_key)]\n",
    "                            if z_sol[(node_curr, node_next, truck_key, cargo_key)] == 1:\n",
    "                                if node_next == cargo_dest:\n",
    "                                    print(f'  ++++++ {cargo_key} from node [{node_curr}] to dest [{node_next}] by Truck {truck_key}')\n",
    "                                else:\n",
    "                                    print(f'  ++++++ {cargo_key} from node [{node_curr}] to node [{node_next}] by Truck {truck_key}')\n",
    "                                print(f'  ++++++ z_sol[({node_curr}, {node_next}, {truck_key}, {cargo_key})] = {z_sol[(node_curr, node_next, truck_key, cargo_key)]}')\n",
    "\n",
    "                                node_curr = node_next\n",
    "\n",
    "                                \n",
    "                            \n",
    "                            if z_temp == 1:\n",
    "                                break\n",
    "                    if z_temp == 1:\n",
    "                        break\n",
    "        else:\n",
    "            cargo_undelivered.append(cargo_key)\n",
    "\n",
    "            # print(f'[{cargo_key}] is not delivered')\n",
    "\n",
    "    for cargo_key in selected_cargo.keys():\n",
    "        for node in selected_node:\n",
    "            if w_sol[(node, cargo_key)] == 1:\n",
    "                print(f'w_sol[({node}, {cargo_key})] {w_sol[(node, cargo_key)]}')\n",
    "                for node_2 in selected_node:\n",
    "                    for truck_key in selected_truck.keys():\n",
    "                        if node_2 != node:\n",
    "                            if z_sol[(node, node_2, truck_key, cargo_key)] == 1:\n",
    "                                print(f'   z_sol[({node}, {node_2}, {truck_key}, {cargo_key})], {z_sol[(node, node_2, truck_key, cargo_key)]}')\n",
    "                            if z_sol[(node_2, node, truck_key, cargo_key)] == 1:\n",
    "                                print(f'   z_sol[({node_2}, {node}, {truck_key}, {cargo_key})], {z_sol[(node_2, node, truck_key, cargo_key)]}')\n",
    "            \n",
    "\n",
    "    print(f'{len(cargo_delivered)} cargo delivered: {cargo_delivered}')\n",
    "    print(f'{len(cargo_undelivered)} cargo undelivered: {cargo_undelivered}')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "check_mip_sol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_pdpt_solution(pdpt_ins, tvopdpt_res, verbose = 0):\n",
    "\n",
    "    selected_cargo = pdpt_ins['cargo']\n",
    "    selected_truck = pdpt_ins['truck']\n",
    "    assert len(selected_truck.keys()) == 2\n",
    "    truck1, truck2 = selected_truck.keys()\n",
    "    selected_node  = pdpt_ins['nodes']\n",
    "    selected_edge  = pdpt_ins['edge_shortest']\n",
    "    \n",
    "    x_sol = tvopdpt_res['x_sol']\n",
    "    z_sol = tvopdpt_res['z_sol']\n",
    "    z_sol = tvopdpt_res['z_sol']\n",
    "    u_sol = tvopdpt_res['u_sol']\n",
    "    w_sol = tvopdpt_res['w_sol']\n",
    "\n",
    "    truck_used = []         # list of trucks used in the solution\n",
    "    \n",
    "    # dictionary, for each truck_key, there is a list of cargo carried that was on this truck. E.g., {'T1\": ['C1', 'C2', ...]}\n",
    "    cargo_in_truck = {}   \n",
    "    for truck_key in selected_truck.keys():\n",
    "        cargo_in_truck[truck_key] = []\n",
    "\n",
    "    # dictionary, for each cargo_key, there is a list of truck that carried this cargo. E.g., {'C1\": ['T1', 'T2', ...]}\n",
    "    trucks_per_cargo = {} \n",
    "    for cargo_key in selected_cargo.keys():\n",
    "        trucks_per_cargo[cargo_key] = []\n",
    "\n",
    "    cargo_delivered = []   # list of delivered cargo\n",
    "    cargo_undelivered = [] # list of undelivered cargo\n",
    "\n",
    "\n",
    "    truck_route = {}\n",
    "    for truck_key in selected_truck.keys():\n",
    "        truck_route[truck_key] = []\n",
    "    cargo_route = {}\n",
    "    for cargo_key in selected_cargo.keys():\n",
    "        cargo_route[cargo_key] = []\n",
    "\n",
    "    # dict, for each cargo_key, there is a nested list, each with [transfer_node, truck_from, truck_to]\n",
    "    cargo_transfer = {}\n",
    "    for cargo_key in selected_cargo.keys():\n",
    "        cargo_transfer[cargo_key] = []\n",
    "\n",
    "    if verbose >0:\n",
    "        print(f'   +++ Process cargo-to-truck-assignment')\n",
    "    # Generate cargo_in_truck\n",
    "    for cargo_key, cargo_value in selected_cargo.items():\n",
    "        cargo_origin, cargo_dest = cargo_value[-2:]\n",
    "        # assert sum([z_sol[(cargo_origin, node_, truck1, cargo_key)] for node_ in selected_node if node_!= cargo_origin]) + sum([z_sol[(cargo_origin, node_, truck2, cargo_key)] for node_ in selected_node if node_!= cargo_origin]) == 1\n",
    "        # assert sum([z_sol[(node_, cargo_dest, truck1, cargo_key)] for node_ in selected_node if node_!= cargo_dest]) +sum([z_sol[(cargo_dest, node_, truck2, cargo_key)] for node_ in selected_node if node_!= cargo_dest]) == 1\n",
    "\n",
    "        for truck_key in selected_truck.keys():\n",
    "            if sum([z_sol[(cargo_origin, node_, truck_key, cargo_key)] for node_ in selected_node if node_!= cargo_origin]) + sum([z_sol[(node_, cargo_dest, truck_key, cargo_key)] for node_ in selected_node if node_!= cargo_dest])  >=1:\n",
    "                cargo_in_truck[truck_key].append(cargo_key)\n",
    "\n",
    "\n",
    "    if verbose >0:\n",
    "        print(f'   +++ Process truck_route')\n",
    "    # postprocess truck_route\n",
    "\n",
    "    for truck_key in selected_truck:\n",
    "        truck_origin, truck_des = selected_truck[truck_key][:2] # starting from the origin node of each truck\n",
    "        print(f'[{truck_key}], origin [{truck_origin}], dest [{truck_des}]')\n",
    "        node_curr = truck_origin\n",
    "        for node_ in selected_node:\n",
    "            if node_ != node_curr and x_sol[(node_curr, node_, truck_key)] == 1: # find node_ such that x[source, node_, truck_key] == 1\n",
    "                print(f'  +++ {truck_key} from origin [{node_curr}] to node [{node_}]')\n",
    "                if len(truck_route[truck_key]) == 0: # append source as the first node\n",
    "                        truck_route[truck_key].append(source)\n",
    "                truck_route[truck_key].append(node_)\n",
    "\n",
    "                node_curr = node_\n",
    "                break\n",
    "        while node_curr != selected_truck[truck_key][1]: # terminate when reach the arival node of each truck\n",
    "            for node_ in selected_node:\n",
    "                if node_ != node_curr and x_sol[(node_curr, node_, truck_key)] == 1: # find node_ such that x[source, node_, truck_key] == 1\n",
    "                    if node_ == truck_des:\n",
    "                        print(f'  +++ {truck_key} from node [{node_curr}] to dest [{node_}]')\n",
    "                    else:\n",
    "                        print(f'  +++ {truck_key} from node [{node_curr}] to node [{node_}]')\n",
    "                    truck_route[truck_key].append(node_)\n",
    "\n",
    "                    node_curr = node_\n",
    "                    break\n",
    "    # RECALL, cargo is a dictionary with the following format:\n",
    "    # cargo['nb_cargo'] = ['size', 'lb_time', 'ub_time', 'departure_node', 'arrival_node']\n",
    "\n",
    "    if verbose >0:\n",
    "        print(f'   +++ Process cargo_route, cargo_delivered and cargo_undelivered')\n",
    "    # truck1, truck2 = selected_truck.keys()\n",
    "    cargo_delivered = []\n",
    "    cargo_undelivered = []\n",
    "    for cargo_key, cargo_value in selected_cargo.items():\n",
    "        cargo_origin, cargo_dest = cargo_value[-2:]\n",
    "        print(f'[{cargo_key}], origin [{cargo_origin}], dest [{cargo_dest}]')\n",
    "        if sum([sum([z_sol[(node, cargo_dest, truck_key, cargo_key)]for node in selected_node if node != cargo_dest]) for truck_key in selected_truck.keys()]) == 1:\n",
    "            cargo_delivered.append(cargo_key)\n",
    "            node_curr = cargo_origin\n",
    "            for node_next in selected_node:\n",
    "                z_temp = 0\n",
    "                if node_next!=node_curr:\n",
    "                    for truck_key in selected_truck.keys():\n",
    "                        z_temp += z_sol[(cargo_origin, node_next, truck_key, cargo_key)]\n",
    "                        if z_sol[(cargo_origin, node_next, truck_key, cargo_key)] == 1:\n",
    "                            print(f'  +++ {cargo_key} from origin [{node_curr}] to node [{node_next}] by Truck {truck_key}')\n",
    "                            if len(cargo_route[cargo_key]) == 0: # append source as the first node\n",
    "                                cargo_route[cargo_key].append((truck_key, node_curr))\n",
    "                            cargo_route[cargo_key].append((truck_key, n_next))\n",
    "                            \n",
    "                        if z_temp == 1:\n",
    "                            break\n",
    "                if z_temp == 1:\n",
    "                    break\n",
    "\n",
    "                    \n",
    "            while node_curr != cargo_dest:\n",
    "                z_temp = 0\n",
    "                for node_next in selected_node:\n",
    "                    if node_next!=node_curr:\n",
    "                        for truck_key in selected_truck.keys():\n",
    "                            z_temp += z_sol[(node_curr, node_next, truck_key, cargo_key)]\n",
    "                            if z_sol[(node_curr, node_next, truck_key, cargo_key)] == 1:\n",
    "                                if node_next == cargo_dest:\n",
    "                                    print(f'  +++ {cargo_key} from node [{node_curr}] to dest [{node_next}] by Truck {truck_key}')\n",
    "                                    cargo_route[cargo_key].append((truck_key, n_next))\n",
    "                                else:\n",
    "                                    print(f'  +++ {cargo_key} from node [{node_curr}] to node [{node_next}] by Truck {truck_key}')\n",
    "                                node_curr = node_next                            \n",
    "                            if z_temp == 1:\n",
    "                                break\n",
    "                    if z_temp == 1:\n",
    "                        break\n",
    "        else:\n",
    "            cargo_undelivered.append(cargo_key)\n",
    "\n",
    "            print(f'[{cargo_key}] is not delivered')\n",
    "\n",
    "    for cargo_key, cargo_value in selected_cargo.items():\n",
    "        cargo_origin, cargo_dest = cargo_value[-2:]\n",
    "        # if cargo is delivered\n",
    "        if sum([z_sol[(node_, cargo_dest, truck_key, cargo_key)] for node_ in selected_node for truck_key in selected_truck.keys() if node_!= cargo_dest]) == 1:\n",
    "            cargo_delivered.append(cargo_key)\n",
    "            print(f'cargo [{cargo_key}] is delivered')\n",
    "\n",
    "            #start from cargo_origin\n",
    "            node_curr = cargo_origin\n",
    "            #check the next node\n",
    "            for n_next in selected_node:\n",
    "                if n_next != node_curr:\n",
    "                    for truck_key in selected_truck.keys():\n",
    "                        if z_sol[(node_curr, n_next, truck_key, cargo_key)] == 1:\n",
    "                            if len(cargo_route[cargo_key]) == 0: # append source as the first node\n",
    "                                cargo_route[cargo_key].append((truck_key, node_curr))\n",
    "                            cargo_route[cargo_key].append((truck_key, n_next))\n",
    "                            node_curr = n_next\n",
    "                            print(f'cargo_origin [{cargo_origin}], node_next[{n_next}]')\n",
    "                            break\n",
    "\n",
    "            while node_curr != cargo_value[-1]:\n",
    "                for n_next in selected_node:\n",
    "                    if n_next!=node_curr:\n",
    "                        for truck_key in selected_truck.keys():\n",
    "                            if  z_sol[(node_curr, n_next, truck_key, cargo_key)] == 1:\n",
    "                                cargo_route[cargo_key].append((truck_key, n_next))\n",
    "                                node_curr = n_next\n",
    "                                break\n",
    " \n",
    "        else:\n",
    "            print([ [truck_key, cargo_key, sum(z_sol[(node_, cargo_dest, truck_key, cargo_key)] for node_ in selected_node if node_!= cargo_dest) ] for truck_key in selected_truck.keys()])\n",
    "\n",
    "            assert sum([z_sol[(node_, cargo_dest, truck_key, cargo_key)] for node_ in selected_node for truck_key in selected_truck.keys() if node_!= cargo_dest]) == 0\n",
    "            print(f'cargo [{cargo_key}] is undelivered')\n",
    "\n",
    "            cargo_undelivered.append(cargo_key)\n",
    "\n",
    "    truck_1, truck_2 = selected_truck.keys()\n",
    "    if verbose >0:\n",
    "        print(f'   +++ Process cargo_transfer')\n",
    "    for cargo_ in selected_cargo.keys():\n",
    "        for node_curr in selected_node:\n",
    "            if u_sol[node_, cargo_key] == 1:\n",
    "                assert sum([z_sol[(node_prev, node_curr, truck_1, cargo_)] for node_prev in selected_node if node_curr != node_prev]) - sum([z_sol[(node_curr, node_next, truck_2, cargo_)] for node_next in selected_node if node_curr != node_next]) == 1\n",
    "                cargo_transfer[cargo_key].append([node_curr, truck_1, truck_2])\n",
    "            if w_sol[node_curr, cargo_key] == 1:\n",
    "                assert sum([z_sol[(node_prev, node_curr, truck_2, cargo_)] for node_prev in selected_node]) - sum([z_sol[(node_curr, node_next, truck_1, cargo_)] for node_next in selected_node]) == 1\n",
    "                cargo_transfer[cargo_key].append([node_curr, truck_2, truck_1])\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "    processed_res = (truck_used, cargo_delivered, cargo_undelivered, cargo_in_truck, truck_route, cargo_route, cargo_transfer)\n",
    "\n",
    "\n",
    "    return processed_res\n",
    "\n",
    "\n",
    "def read_result():\n",
    "    case_num, ins_idx, num_trucks = 1, 0, 2\n",
    "    \n",
    "    pdpt_ins_filename = os.path.join(dir_, f'data/case{case_num}', f'case{case_num}_truck{num_trucks}_ins{ins_idx+1}.pkl')\n",
    "    pdpt_ins = read_pickle(pdpt_ins_filename)\n",
    "    \n",
    "    print('=== summary of pdpt_ins')\n",
    "    print('\\t[', len(pdpt_ins['cargo'].keys()),'] cargos, [', len(pdpt_ins['truck'].keys()),'] trucks')\n",
    "    res_filename = os.path.join(dir_, f'data/case{case_num}', f'case{case_num}_truck{num_trucks}_ins{ins_idx+1}_res.pkl')\n",
    "    tvopdpt_res = read_pickle(res_filename, verbose = 0) \n",
    "    print('=== Start Postprocess mip sol')\n",
    "    processed_res  = postprocess_pdpt_solution(pdpt_ins, tvopdpt_res, verbose = 1)\n",
    "    \n",
    "    truck_used, cargo_delivered, cargo_undelivered, trucks_per_cargo, cargo_in_truck, truck_route, cargo_route, cargo_transfer = processed_res\n",
    "\n",
    "    print(f'+++ list of cargos sucessfully delivered \\n{cargo_delivered}')\n",
    "          \n",
    "    print(cargo_undelivered)\n",
    "    \n",
    "# read_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c1990874c5d43c5ad255fb4eddb2910398111b9d51d69584c4b5152ab9b533bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
